<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en">
<head>
<title>1 Visual Knowledge (or Graphesis): Is Drawing as Powerful as Computation?</title>
<meta content="text/html; charset=utf-8" http-equiv="default-style"/>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:ab716dc3-7c3d-4fc9-9c55-4cc6a0edf9ef" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter">
<div class="body">
<p class="sp"> </p>
<section aria-labelledby="ch1" epub:type="chapter" role="doc-chapter">
<header>
<h1 class="chapter-title" id="ch1"><span aria-label="11" id="pg_11" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">1    Visual Knowledge (or</samp> <samp class="SANS_ITC_Stone_Sans_Std_Semibold_Italic_BI_11">Graphesis</samp><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">): Is Drawing as Powerful as Computation?</samp></h1>
</header>
<p class="noindent">We are not necessarily accustomed to thinking about visual images from a theoretical perspective rooted in problems and questions of knowledge. And yet, visual images have capacities for production and presentation of knowledge that are unique and also fully integrated into common understanding and daily activity across a wide range of disciplines. Let’s begin by addressing the status of visual epistemology directly and then return to problems of digital work and humanistic interpretation.</p>
<p>Visual expressions serve not merely as representations of existing knowledge, but as primary modes of knowledge production. They have the capacity to produce and embody information, not just represent it. This assertion suggests that experience, feeling, sentiment, conceptual and intellectual schemes can be expressed as visual statements (in a declarative manner). But it also asserts the capacity to make claims (propositional statements) or provocations that may be tested, justified, or argued using visual evidence. Visual epistemology, therefore, can be both declarative/descriptive and propositional/provocative. Demonstrating that this is the case is the task here, and showing the ways that visual images perform their epistemological work is central to the argument.</p>
<p>Before beginning, a general statement should be made to clarify the distinction between representational and nonrepresentational approaches to visual forms of knowledge, since the contrast may be unfamiliar. Representational forms assume a secondary status; they are surrogates, and stand for a preexisting, a priori, already formulated knowledge in the form of a graphic statement, notation, or visual phenomenon of some kind. A map may represent a territory (even though it contains the distortions of projection systems and of course many features that never show up in the <span aria-label="12" id="pg_12" role="doc-pagebreak"/>physical environment—approaching a state capital on a highway one does not see a giant star in the landscape, for instance). Similarly, a portrait may represent a specific person, a graph may represent a data set, and an anatomical drawing may represent a body or its systems and parts realistically or schematically. These are common representations. They are not equivalents. They are not identical to what they represent. They are surrogates that exist in various degrees of remove and transformation from what they reference. They translate knowledge into visual form.</p>
<p>A nonrepresentational visual expression creates information or knowledge in a primary mode. An architectural sketch <i>brings forth</i> the image of a building, a geometrical diagram <i>creates</i> a proof, a drawing <i>produces</i> a form hitherto unknown, an act of connecting one or more words in a text with a line <i>creates</i> an interpretation, or a drawing of an arrow <i>creates</i> a model of time or temporality. In these examples, the production of the visual image produces something new, it does not reproduce something preexisting. Graphical calculus, in a precomputational era, was a means of arriving at results, not a method of simply displaying them.</p>
<p>This distinction matters because while the representational role of visual images is well known and understood, the nonrepresentational aspect is less familiar. Representational images have a relation to an existing referent (something to which it refers). But the nonrepresentational status of visual images (which seems counterintuitive at first as a notion) is harder to grasp. Images always seem to suggest a relation to an existing referent (they <i>seem</i> premised on resemblance). But does a visual expression always have to be dependent on a preexisting referent? At stake in answering this question is the claim that graphical work <i>is</i> intellectual work, as a primary mode—a claim supported by practitioners across a wide array of fields from theoretical physics to engineering and design, as well as those in the conceptual and visual arts. If we modify this argument one step further, with the constraint that the main interest here is to address ways in which humanistic approaches to visualization express an interpretative approach to knowledge, then our scope narrows. But support for the experimental work follows. Before we can engage in detail with these particular and focused concerns, a more general view of visual epistemology needs to be put into place.</p>
<section epub:type="division">
<h2 class="head a-head"><span aria-label="13" id="pg_13" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Visual epistemology</samp></h2>
<p class="noindent">The range of disciplines that make use of visual approaches to epistemology is broad, and issues of style should not be allowed to confuse the basic functions of images. This remains true at the specific intersection of digital methods and visual forms of knowledge production and interpretation. The capacity of images to present knowledge is not a matter of form, but of the relation of images to referents: knowledge can preexist and be shown or be created by the image.</p>
<p>Graphical forms include any visual arrangement of marks or visual forms on a support surface or substrate (paint on canvas, pen on paper, pixels on a screen). These forms are literal and visible and need not be put at the service of pictorial illusion. All graphical artifacts are comprised of marks or traces organized on a surface (broadly construed to include a wide range of materials, projections, immersive environments, and so on). They embody knowledge through the combination of symbolic codes and structured relations of these elements in a field. Individual visual instances (a graph, a drawing) can change over time, either through accretion or deletion. But methods of making graphics also change with conceptual and technological innovations, such as occurred with the invention of animation.</p>
<p>Graphical knowledge cannot be grasped in any self-evident way. For one thing, images have no simple correlation to language—no single word can be used as the equivalent of a single line, even if language can be used to describe it. On its own, a line or mark can be highly ambiguous—highly specific and infinitely unique. Like any other form of human expression—natural or formal language, mathematical notation, bodily gestures, or other signs and codes—visual imagery becomes more stable and more useful when interpreted in combination with a linguistic gloss or statistical base. This statement doesn’t negate the specific properties of visual forms—many of which have no equivalent in language or formal systems. But it should put to rest any lingering na<span class="dcrit">ï</span>ve formalism premised on the idea that visual representations communicate directly and simply. Images are not self-evident. We learn to interpret them through learned approaches to encoded expressions that provoke a response for cognitive processing. In other words, reading images is an acquired skill embedded in cultural and historical circumstances.</p>
<section epub:type="division">
<h3 class="head b-head"><span aria-label="14" id="pg_14" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Visual and digital</samp></h3>
<p class="noindent">Visual forms of knowledge production do not depend upon digital techniques. We use visual skills to distinguish faces, read graphic novels, and navigate a complicated route without any digital technology. But computational capabilities offer unique opportunities to make use of visual methods. Not only are screens and devices organized with graphical interfaces, but the processing of information in digital form makes it easy to create visual displays for all kinds of purposes. Conventions for graphical display have become familiar, legible, easy to read—and equally easy to take for granted. We hardly see the workings of visualizations and take their forms for mere statements, representations of information with which we quibble for their accuracy or effectiveness, while ignoring the larger issues of knowledge claims embedded in their use.</p>
<p>But received conventions can be extended to model generative and/or interpretative, as well as representational, approaches. Much is contained in that statement, and it will need to be carefully expanded. Even the most basic aspect of my argument—that visual methods can <i>produce</i> knowledge and <i>enact</i> interpretation, not just serve as representations or displays—is considered polemical by many.<sup><a href="chapter_1.xhtml#chapter1-1" id="chapter1_1" role="doc-noteref">1</a></sup> To insist, further, that interpretative methods have their own specific requirements and possibilities, that these are rooted in probabilistic hermeneutics and critical theory specific to the humanities, only multiplies the challenges. In this first section, I will address the basic issues of visual knowledge in digital environments, leaving the discussion of probabilistic approaches for the next chapter and the nonrepresentational modeling approach for the one after.</p>
<p>A political agenda inheres in this project, which is to demonstrate that value-laden (ideological) operations of knowledge production can be exposed through methods that attend to the historically situated, culturally located, and individually inflected systems (described above as <i>systems of enunciation</i>) within which they work. Attending to these ideological operations is not the exclusive responsibility of humanists, but I would argue that humanists possess methodological tools that are particularly well suited to this task. The connection between these tools and the terms on which visual expressions function in digital work is direct. Ideology (cultural value) appears in every graphic, layout, format, bit of iconography (as well as in interface and navigational features to be addressed in a later section), even as it disappears through the familiarity of conventions.<sup><a href="chapter_1.xhtml#chapter1-2" id="chapter1_2" role="doc-noteref">2</a></sup></p>
<p><span aria-label="15" id="pg_15" role="doc-pagebreak"/>The first challenge is to address the question of whether images produce knowledge, and if so, how and what kind? Is there a specific <i>visual</i> epistemology? Following this, we can ask how engagements with modeling interpretation might extend or challenge graphic conventions used in digital humanities. The specificity of visual epistemology and the particulars of graphical means feature in this argument, but these are concepts that do not belong specifically to the digital realm.<sup><a href="chapter_1.xhtml#chapter1-3" id="chapter1_3" role="doc-noteref">3</a></sup> The principles of <i>graphesis</i> as the basic concept of visual forms of knowledge production will be dealt with more summarily here, while the relation between visuality, interpretative methods, and digital humanities will be brought to the fore.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Visuality, perception, and cognition</samp></h3>
<p class="noindent">Human cognitive and perceptual capacities make use of vision for a range of complex activities that have nothing to do with images. The literature on vision and the brain is supported by empirical experiments that explore these capacities in a scientific way.<sup><a href="chapter_1.xhtml#chapter1-4" id="chapter1_4" role="doc-noteref">4</a></sup> The historicity of vision and cultural conditions of perception also factor into these studies.<sup><a href="chapter_1.xhtml#chapter1-5" id="chapter1_5" role="doc-noteref">5</a></sup> But the connection between vision and knowledge explored here is not grounded in perception as a physiological fact. Instead, it is focused on the ways that specific properties of graphical inscription and notation can be contrasted with those of binary code in terms of their inherent qualities as well as critical approaches. In other words, my attention is on the knowledge-producing (epistemological) properties of graphical images in digital environments, rather than on the mechanical study of eye-tracking or click counts and other studies of visual processing.</p>
<p>As already noted, a vast inventory testifies to the long-standing relation between knowledge and images. This includes scientific illustration, maps, charts, graphs and diagrams of all kinds—from those charting blood flow and plant morphology to ones used to track the movement of stars in the heavens and orient sailors toward their destinations.<sup><a href="chapter_1.xhtml#chapter1-6" id="chapter1_6" role="doc-noteref">6</a></sup> It also includes account books, civic monuments, architectural plans, and city signage as evidence of knowledge structured visually and organized graphically. The list could proliferate endlessly. Most would agree that these images serve to represent knowledge within a wide range of disciplinary domains, but precisely how they are themselves <i>arguments</i> about knowledge or belief, or are able to <i>produce interpretation</i> is less clear. Current work on the way scientific illustration and natural history are bound together has advanced <span aria-label="16" id="pg_16" role="doc-pagebreak"/>these insights, but the underlying assumptions of this line of scholarship privilege scientific understanding as a legitimating factor in assessing the images.<sup><a href="chapter_1.xhtml#chapter1-7" id="chapter1_7" role="doc-noteref">7</a></sup> The value of the images rests on their capacity to communicate information in accord with supposedly neutral assessments of “accuracy.”</p>
<p>The long-standing realization that direct observation is insufficient to ensure accurate perception or depiction can be amply illustrated. Whether we look at the peculiar historical drawings made from beached whales that provide them with fanciful fangs, or see the detailed male genitalia observed on mandrake roots, or wonder at our inability to see a figure in the gorilla suit walking through a group of basketball players in a viral video, we see the limits of assuming any direct encounter between perception and cognition.<sup><a href="chapter_1.xhtml#chapter1-8" id="chapter1_8" role="doc-noteref">8</a></sup> No “innocent eye,” exists, as the twentieth-century art historian and psychologist Ernst Gombrich’s characterization of this mythic notion made clear.<sup><a href="chapter_1.xhtml#chapter1-9" id="chapter1_9" role="doc-noteref">9</a></sup> We see what we know and what we expect to see as much as we process phenomena according to their visible features. Theories of vision go further than this mere qualification of direct observation into psychoanalytical, anthropological, sociological, and ecological realms. For instance, James J. Gibson, with his theory of ecological vision, describes the combination of selective and adaptive characteristics that are combined in visual processing.<sup><a href="chapter_1.xhtml#chapter1-10" id="chapter1_10" role="doc-noteref">10</a></sup> Not only do we learn to see in accord with our species-specific needs, but individuals also “learn” to see differently. Further experimentation notes that the eye itself changes, as does the full visual system, when exposed to particular stimuli.<sup><a href="chapter_1.xhtml#chapter1-11" id="chapter1_11" role="doc-noteref">11</a></sup> The codependent nature of the perceptual and cognitive psycho-physiological system shaped by behavior and experience, as well as psychological patterns and dispositions, is further complicated by the integrative work of the cerebral cortex, which processes several sensory inputs in its activity in a process referred to as multisensory integration. So, not only do graphical modes have the capacity to produce interpretative models of experience, the visual sensorium is itself an interpretative system and one that is modeled by the multifaceted features of perception and cognition across sensory inputs.</p>
<p>Within the discussion of scientific images, intellectual value is always assessed with a single criterion: how well do works of artists in a particular period conform to or reflect contemporary scientific attitudes toward knowledge? Questions of aesthetics factor into the discussion only with respect to the task the images are presumed to serve. Take Claudia Swan’s discussion of color in drawings of plant species, for instance. As she reports <span aria-label="17" id="pg_17" role="doc-pagebreak"/>in a study of botanical illustrations, eighteenth-century scientists chided the artists who were drawing renderings of specimens for creating misinformation through their use of (observed) color variation. The color created the impression that these drawings were records of multiple species when they were clearly merely individual instances of a single species with shared morphological structure.<sup><a href="chapter_1.xhtml#chapter1-12" id="chapter1_12" role="doc-noteref">12</a></sup> Swan’s discussion does not challenge the botanists’ claims to cultural authority, working as it does within empirical approaches. She is an art historian, not a scholar of science and technology. She does not question the empirical accuracy accorded to scientific knowledge. In her view, epistemological authority resides unquestionably in the correlation of image and object on terms determined by scientists. They assume that an object can be perceived objectively, independent of a user’s own historical disposition. This assumption permeates the historiography of work on images in the service of botanical, medical, and zoological knowledge across the realms of “natural” history. The question of what other epistemologies might be available in these historical and cultural moments is never asked. What other models of knowledge and visuality might be considered besides those of empirical science? How might this change with a consideration of phenomenological approaches, for instance, or emotional or symbolic ones? Is the ability to read the properties of a particular pressed-flower specimen (the moment of its being found and preserved) or discern a particular kind of damage (sign of a large animal or of a mower) a form of knowledge? This is a question about the status of knowledge, not merely its visual expression. In the empirical sciences, the <i>only</i> form of knowledge that matters is that which is objective, user-independent. The attitude is premised on belief in perception as direct and uninflected by cultural conditions. The claim is that empirical knowledge operates authoritatively without historical or cultural assumptions or influence. Such an attitude serves a purpose within certain domains, but does not exhaust the capacities of images to generate knowledge. Visual epistemology has long been subject to these powerful belief systems, seriously limiting discussion of properties of visual rhetoric and inscriptional specificity (the unique properties of each instance of graphic work). The empirical tradition ignores (and delegitimizes) knowledge grounded in nonempirical methods, even though textual and cultural studies have long ago exposed the limitations of empirical claims to universal truth—and the biases and blind spots on which they operate.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><span aria-label="18" id="pg_18" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Images of nonvisible phenomena</samp></h3>
<p class="noindent">Many aspects of natural, social, or cultural phenomena have no visual corollary. Even in the physical sciences, recording the work of forces, vectors, atmospheric and thermal conditions, and so forth is dependent on various conventions, not observation. For instance, contour lines that show altitude on maps, and wind arrows, isobars, and high- and low-pressure systems are all presented in graphical codes, but that does not make them “real” parts of the natural system.<sup><a href="chapter_1.xhtml#chapter1-13" id="chapter1_13" role="doc-noteref">13</a></sup> Peter Galison has traced tensions between two research traditions in the sciences that make use of images—pictorial presentation and computational production—as dual parts of an epistemic practice that structured much of the experimental activity of modern physics.<sup><a href="chapter_1.xhtml#chapter1-14" id="chapter1_14" role="doc-noteref">14</a></sup> The image of the atom as a small solar system of particles in orbit, for instance, is not based on observation, but on an idea of how to represent a model of a phenomenon. The creation of images, such as traces in a cloud chamber, may affirm or undermine a theoretical hypothesis. But conceptualization of phenomena is often as strongly influenced by the models made as by observation (think of gender categories as an example where changing models have changed perception). Lab work may be done visually or it may use visual methods just to show results (such as the display of changes in temperature across time). This is true in the humanities and social sciences, and the role of visualizations in reification of constructs and concepts is powerful. Even very basic features, like the separation of temporal intervals into years or days carries assumptions that may or may not accurately reflect the phenomenon being represented in these graphical-conceptual structures. Our understanding of forms of knowledge is often only a knowledge of forms (or, to put it another way, <i>how</i> we know often shapes <i>what</i> we know). Recent experiments in creating novel structures in organic chemistry, or biological organisms through visualization techniques, suggest that the manipulation of visual models to generate new structures is making aesthetic research a vital part of scientific innovation. Properties and behaviors get defined as an effect, not an a priori given, in ways that have been a part of architecture and applied design for centuries.</p>
<p>Mathematics is full of graphical forms that do meaningful work, such as matrices or formulae. These support high-level operations and manipulations. As already noted, visual conventions for such familiar procedures as adding or subtracting numbers, or using decimal points to define place-specific values are taken almost for granted though they perform essential <span aria-label="19" id="pg_19" role="doc-pagebreak"/>functions. Formal structures like Venn diagrams provide dramatic examples of expressions that <i>do</i> the work they express; they do not simply represent it. And in the specialized field of visual calculus (mentioned above), graphical methods were used to find solutions to complex problems before computers were capable of automating these procedures.<sup><a href="chapter_1.xhtml#chapter1-15" id="chapter1_15" role="doc-noteref">15</a></sup> The rationalization of surface as a ground on which to work (by the use of grids, or metrics, or values on an <i>x</i> or <i>y</i> axis), and which provides a stable space for graphical presentation, is so fundamental we forget to regard it as a conceptual act that advanced knowledge. Similarly, the creation of ground lines for production of straight lines of glyphs, cuneiform marks, or early writing, established conventions of linearity that still prevail.<sup><a href="chapter_1.xhtml#chapter1-16" id="chapter1_16" role="doc-noteref">16</a></sup> Likewise, the hierarchy of top and bottom, the dominance of left-to-right reading in much of western culture, and other structuring principles of graphical systems are embedded in the visualizations we use almost without thinking.</p>
<p>In addition to contemplating the semantics of format and arrangement, we can consider the basic forensic evidence of graphics, the indexical traces of events or activities left behind as lines or marks. These marks provide evidence, ways to read back into events and to reconstruct them. The trace of a signature, the imprint of a seal, or the scuff marks on a section of wall or floor are all indexical signs. Anthropologists read the markings on walls, the imprints of hands, feet, and bodies in hollows and seats around a site, according to their graphical properties to discern meaning and value. The marks of editing, reworking, and rewriting that accumulate on a manuscript are also read as graphical traces of past events. These require systematic decoding and analysis in other systems of description that are in turn organized with graphical means for critical editing and bibliographical work. The information embodied in formatting features contains codes for reading, instructions on how to interpret each word or line depending on its placement. We rarely pause and consider these codes—or the multiple ways in which our reading of any text or image is governed by the site in which it appears. Formal, official, domestic, educational, public, bureaucratic frameworks—we read these conditions in moving from context to text and back again.</p>
<p>But, as already hinted, graphical form can also be a semantic, original, and primary means of generating knowledge. Consider the task of creating a plan for a building, sketching the design of a traffic system or a workflow diagram. These methods bring into being something that has not existed <span aria-label="20" id="pg_20" role="doc-pagebreak"/>before. The image contains information that cannot be replicated very readily in textual or numerical form. If I want to chart a path or create an instruction sheet for dance steps, verbal description is best as a supplement, not a primary mode of knowledge production. An implied question is embodied in every napkin sketch of an imagined structure or product outline: “Will this work?” In essence, each sketch is a visual thesis, a proposition about possibilities of knowledge that would have to be tested with evidence to see if it is a justified belief.</p>
<p>All of these practices—scientific illustrations, traces, encoding, experimentation—are part of the inventory of methods of graphical epistemology.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Aesthetic images as knowledge arguments</samp></h3>
<p class="noindent">In addition to images from science, engineering, or other realms where they serve applied tasks, another inventory of visual knowledge is contained in the history of artworks. These images are rarely approached as knowledge objects, but instead, are studied for their style, form, provenance, social impact and influence, content, iconography, theme, treatment, composition, authorship, ideology, politics, influence, forgery and a host of other considerations. These issues eclipse attention to epistemological claims when dealing with art historical and aesthetic works. In fact, the very question of whether an image makes an argument or embodies justified claims of belief occupies only a small number of art historians and theorists. And yet, it can be argued that every visual image makes an implicit or explicit argument about visual knowledge and the terms on which the relation between knowledge and its production and presentation are understood.<sup><a href="chapter_1.xhtml#chapter1-17" id="chapter1_17" role="doc-noteref">17</a></sup> A single example will serve to make the general case.</p>
<p>The example focuses on two images by Rembrandt—a <i>Self-Portrait</i> of the still-young artist (1627) and <i>The Anatomy Lesson of Dr. Nicolaes Tulp</i> (1632).<sup><a href="chapter_1.xhtml#chapter1-18" id="chapter1_18" role="doc-noteref">18</a></sup> They are relatively close in time to each other, especially given Rembrandt’s long career. But they are stylistically distinct in deliberate and significant ways that, I suggest, have to do with their epistemological assumptions. In the self-portrait, the shadowed eyes, blurred focus, and obscured brow of the young Rembrandt pose the question of whether or not—and <i>how</i>—one might know and picture one’s own identity, one’s “self,” in any objective way.<sup><a href="chapter_1.xhtml#chapter1-19" id="chapter1_19" role="doc-noteref">19</a></sup> The confusions of self-perception are posed visually, as questions of knowledge, in ways that cannot be easily resolved. What can be seen? How is perception able to function independent of the confusions that cloud the <span aria-label="21" id="pg_21" role="doc-pagebreak"/>visual apparatus with subjective judgments? In the early self-portrait, the artist is so far within his own self-perception that he focuses on <i>that</i> as the very theme of the work. He makes a vivid argument for <i>observer-dependent knowledge</i>, the very condition of being within the interpretative process, by giving visual expression to this question: Can a subject know himself or herself as an object?</p>
<p>That absence of resolution with respect to the relation between perception, knowledge, depiction, and identity of the subject as object is in direct contrast to the detailed and nearly surgical inscription of the individual portraits of each of the figures in the <i>Anatomy Lesson.</i> If the self-portrait is a study in modeling a subjective position, the <i>Anatomy Lesson</i> is a demonstration of belief in empirical approaches to knowledge. With evident faith in the capacity of vision to be as precise in its relation to an object as the surgical instruments that are laying bare the sinews and muscles of the arm for clear examination, Rembrandt shows us the identities of the medical figures through depiction of their features. They are knowable by their physiognomies, and these can be represented, objectified, made into images. The terms of knowing and recognition are visual, as is the anatomical knowledge offered by the depiction of the corpse and, presumably, the book propped open at its feet and the document held in hand by one of the observing physicians. Forms of visual knowledge and commentary upon their workings into and as images are multiplied in these two works, and the contrast could support a much longer discussion.</p>
<p>But the principle at work here—that images embody assumptions about knowledge—can be broadly applied. All images embody assumptions about visual epistemology—its limits and capacities, and its specificity. A study of an early modern work by Paul C<span class="dcrit">é</span>zanne could call forth a different but equally pointed set of observations about the assumptions of knowledge on which it is based, as could a satirical work by William Hogarth, a portrait by Alice Neel, or a conceptual work by Robert Gober. C<span class="dcrit">é</span>zanne asks how we can know the volumes of air, space, and objects as components of the world and find a language adequate to express them. Neel suggests that all sitters reveal the contradictions of what is apparent and what is concealed by appearances. Hogarth shows that knowledge is circumscribed by convention: the patterns and orders we perceive may be as deceptive through their framing as the position of objects in his 1754 satire on visual perspective. Or pretensions and affectations may be concealed by the codes of dress and <span aria-label="22" id="pg_22" role="doc-pagebreak"/>decorum of the figures whose worlds he depicts. Gober shows how vision encodes cultural bias, and then surprises us with alternatives that show the depth of these entanglements.</p>
<p>For Rembrandt, degrees of focus and precision of delineation are visual methods in the service of his argument about differences in types of knowledge, those of self-observation and observing subject. His argument is made in his <i>methods</i>, not only the composition or iconography he uses. The two images offer their crucial contrast graphically—between the contingencies of a situated, hermeneutic knowledge and that of a presumed objectivity, (fictively) independent of an observer. He differentiates these positions through the vague blurring of one and the tight finish of the other. The self-portrait is a demonstration of the way the conditions of user-dependent interpretation can be exhibited, called to attention as situated knowledge that cannot come into focus because there is no “outside” place of observation. The self-portrait is always inside of the hermeneutic process in ways that are inescapable.<sup><a href="chapter_1.xhtml#chapter1-20" id="chapter1_20" role="doc-noteref">20</a></sup> The portraits in <i>Anatomy Lesson</i> demonstrate the presumption of observer-independent knowledge, as if these figures would have the same appearance under any circumstances and in the gaze of any observer—and as if identity were isomorphic to physiognomy carefully observed.</p>
<p>Not every image poses explicit questions about observer-dependent and observer-independent approaches to knowledge. But every image (as suggested in the cursory sketch above) is premised on one or the other of these positions and accompanying issues of the construction of vision, its cultural features, historicity, and psychological aspects. If the long history of connections between seeing and knowing can be teased from any and every instance of visual expression, then how does the use of digital imagery push these concerns? How does the difference between visual forms and expressions used <i>to model interpretation</i> and those used <i>to visualize information</i> become formulated within a discussion of long-standing concepts of <i>mathesis</i> in relation to those of <i>graphesis</i> specifically with respect to digital environments? The term <i>mathesis</i> describes a system that represents knowledge with the same formal explicitness and lack of ambiguity as mathematical notation. Its symbols are repeatable and always have the same value. By contrast, <i>graphesis</i> describes a system in which every instantiation is specific, characterized (however minutely) by individual differences.</p>
</section>
</section>
<section epub:type="division">
<h2 class="head a-head"><span aria-label="23" id="pg_23" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_Italic_BI_11">Mathesis</samp> <samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">and</samp> <samp class="SANS_ITC_Stone_Sans_Std_Semibold_Italic_BI_11">graphesis</samp></h2>
<p class="noindent">In the late 1970s and early 1980s, the proliferation of digital platforms was accompanied by a flurry of theoretical characterizations of code as “pure difference.”<sup><a href="chapter_1.xhtml#chapter1-21" id="chapter1_21" role="doc-noteref">21</a></sup> This idea of a “pure” difference, one that was constituted without material instantiation, was completely false, but it found many eager advocates nonetheless. A handful of citations suffices to show the stubborn persistence of these notions. For example, take Garfield Benjamin’s statement: “Binary logic is built upon the purely formal numbers one and zero, exemplifying Deleuze’s pure difference and <span class="dcrit">Ž</span>i<span class="dcrit">ž</span>ek’s minimal difference, functioning as the coalescence of meaning with the real in the fundamental positing of a digital universe, virtual-existence then appears as a realm of the imaginary in the superficial light of the interface screen.”<sup><a href="chapter_1.xhtml#chapter1-22" id="chapter1_22" role="doc-noteref">22</a></sup> Or, Michael Eldred’s: “Basically, an ordered sequence of zeroes and ones (nothing and something, pure difference) is transmitted which at the other, recipient’s end can be and must be recomposed in such a way that the appropriate result <span class="ellipsis">…</span> is brought about.”<sup><a href="chapter_1.xhtml#chapter1-23" id="chapter1_23" role="doc-noteref">23</a></sup> And Alain Badiou’s: “It so happens that the difference between zero and one is very important in our digital world. The basic difference between zero and one is the origin of all differences, it is pure difference, the paradigm of all differences, as we see with the concrete example of the development of binary code.”<sup><a href="chapter_1.xhtml#chapter1-24" id="chapter1_24" role="doc-noteref">24</a></sup></p>
<p>The mythology and misunderstanding in these statements expose a long-standing philosophical prejudice against materiality (not only in its graphical form), as if the horrors of embodiment could be fully avoided at last. The “purity” of code, these approaches implied, inscribes ideas in an “immaterial” form. This pure form, mathematical—metaphysical—in its logical structure, could triumph over the base stuff of physical embodiment. We might imagine that the awful dross of the material world, with its bodily associations, could at last be discarded and disregarded. Ignorance of the complicated materiality of digital technology underpins this belief, but that is of less importance than the impulse to embrace an abstraction rooted in a value system of purity associated with distance from material instantiation.</p>
<p>In western thought, images have long been associated with idolatry and temptations of the flesh. We have only to conjure the image of the Golden Calf from the Old Testament to see how images are associated with practices that turn a people toward adoration of an idol and away from worship of an ineffable deity. Platonic hierarchies, later absorbed into Judeo-Christian <span aria-label="24" id="pg_24" role="doc-pagebreak"/>ones, consider images a debased version of ideas which alone can approach truth. When truth is understood as universal, and faith is premised on the ineffable, these tenets of belief hold as foundations of knowledge as well as other forms of belief. The idea that knowledge might be specific, local, contingent, instantiated, and associated with sense perception and cognition is at odds with these traditions and their highly influential premises. Images are stigmatized by this kind of theological and philosophical baggage. This led to assumptions that digital images, because of their relation to “immaterial” code, might not be. Here we see the persistence of rhetoric to affirm the new “purity” of code as “difference.” The fact that this “difference” had to be embodied in complex layers of silicon, software, platforms, devices, displays and so on was conveniently overlooked.</p>
<p>Perhaps more important than the characterization of code as “pure difference” is the contrast we can make between <i>mathesis</i> as basic binary code (formal, mathematical, logic meant to serve to inscribe all knowledge in a single, unambiguous, logical form) and <i>graphesis</i> as an inscription that either produces or represents information and/or knowledge in visual form through those properties of variety and specificity mentioned at the outset. Significantly, the investigation of <i>graphesis</i> will provide a way to return materiality to code, rather than the contrary, while also distinguishing it from <i>mathesis</i> according to the criteria of formal structure, ontological identity, and performative capacity.</p>
<p><i>Mathesis</i>, as already noted, is defined as “knowledge represented in mathematical form, with the assumption that it is an unambiguous representation of thought.”<sup><a href="chapter_1.xhtml#chapter1-25" id="chapter1_25" role="doc-noteref">25</a></sup> It embodies the attempt to engage a formal system of knowledge production that follows the laws of mathematical logic applied across many other domains of knowledge production.<sup><a href="chapter_1.xhtml#chapter1-26" id="chapter1_26" role="doc-noteref">26</a></sup> The goal of <i>mathesis</i> was disambiguation, clarity, and precision of expression and combination. Unlike the messy reality of natural language, a completely formal language would make use of all of the properties of logic and mathematics to compute ideas, arrive at irrefutable conclusions, even calculate outcomes of moral and theological debates. This quest for the “laws of thought” through this formalization of knowledge has a long history, but the term <i>mathesis universalis</i> is associated with Gottfried Leibniz and Ren<span class="dcrit">é</span> Descartes.<sup><a href="chapter_1.xhtml#chapter1-27" id="chapter1_27" role="doc-noteref">27</a></sup> Their quest for a universal mathematical system also coincided historically with a political desire to communicate across language groups and cultures. <i>Mathesis</i> was supported by the utopian dream of utterly clear and universal communication.</p>
<p><span aria-label="25" id="pg_25" role="doc-pagebreak"/>These quests gave rise to several of the universal language schemes and innovative sign systems that proliferated in the seventeenth and early eighteenth centuries as philosophical experiments. A handful, like the extensive project of Bishop John Wilkins, were designed so that they embodied the structure and organization of classification systems as a kind of visual code.<sup><a href="chapter_1.xhtml#chapter1-28" id="chapter1_28" role="doc-noteref">28</a></sup> In such a code, the category of plants could be indicated by an upright stroke, and animals by a horizontal one. Details of the place of any specimen within the hierarchy of other members of its kingdom was indicated by other strokes, dots, and features. The aspiration was for a “word’s” value or meaning to be deciphered directly, by decoding its place in this system. Each category—animate or not, animal or vegetable, vertebrate or invertebrate and so on—would be encoded in legible signs.<sup><a href="chapter_1.xhtml#chapter1-29" id="chapter1_29" role="doc-noteref">29</a></sup> The many fallacies and assumptions in this approach include a conviction that language mainly represents things and that ideas are universal, cross-cultural, and objectifiable within stable and discrete logical systems. This quest—for signs that could communicate directly to the eye—was also partially inspired by a misunderstanding of the pictorial qualities of hieroglyphics as well as Chinese characters, both of which were taken to represent things unambiguously.<sup><a href="chapter_1.xhtml#chapter1-30" id="chapter1_30" role="doc-noteref">30</a></sup> These popular misunderstandings were widespread in the late Renaissance, and persisted into twentieth-century work by, for instance, Ernest Fenollosa, the scholar who had such a strong influence on poet Ezra Pound’s idea of the ideogram.<sup><a href="chapter_1.xhtml#chapter1-31" id="chapter1_31" role="doc-noteref">31</a></sup> In the case of Leibniz’s system, the goal was to create a formal system to calculate thought (or in which thought could be computable), not just represent things. His interest in the power of the <i>I Ching</i> as a combinatoric system was an inspiration for this approach. The quest for a universal, visual character and for a computable formal system of communication shared certain convictions about the character of mathematical notation and its logical systematicity.</p>
<p>This quest to discover an analogy between logic and thought persisted well into the twentieth century. Some projects were inspired by nineteenth-century figures like George Boole. His 1854 work <i>An Investigation of the Laws of Thought</i> is a precursor to the logical positivism that informed much of Anglo-American philosophy, Vienna School studies of language and sign systems, and models of computer intelligence.<sup><a href="chapter_1.xhtml#chapter1-32" id="chapter1_32" role="doc-noteref">32</a></sup> These philosophers did not confuse thought, a mental process, with formal logic as a representational system, but in popular perception this became the case as computers became widespread. The work of many early researchers in artificial <span aria-label="26" id="pg_26" role="doc-pagebreak"/>intelligence, such as Norbert Wiener, was premised on a belief that the human brain could be compared to a computer and that a formal system might be developed to serve as a corrective to the faultiness of natural language with its embedded dependence on circumstances and nuances of communication.<sup><a href="chapter_1.xhtml#chapter1-33" id="chapter1_33" role="doc-noteref">33</a></sup></p>
<p>These multiple strains of intellectual inquiry all have a place within the larger framework of <i>mathesis</i> understood broadly as the belief that the authority of logical, formal structures inheres in their capacity to both create and represent knowledge in expressions that have no ambiguity to them, that are computable, and that are completely independent of their circumstances of use. The brain-computer comparison became the object of criticism from a range of philosophical viewpoints, famously, those of John Searle and Hubert Dreyfus.<sup><a href="chapter_1.xhtml#chapter1-34" id="chapter1_34" role="doc-noteref">34</a></sup> Searle’s “Can Computers Think?” was an argument against artificial intelligence based on a distinction between mechanistic processing and human capacities for intellectual thought.<sup><a href="chapter_1.xhtml#chapter1-35" id="chapter1_35" role="doc-noteref">35</a></sup> Dreyfus’s <i>What Computers Can’t Do</i> (1972) was premised on the distinction between symbol manipulation in formal systems and unconscious intuition as well as embodied and lived experience as a foundation for human thought. His landmark work has featured in many debates that still swirl around comparisons between human brains and computational processes.</p>
<p>Now we can turn to a critique of <i>mathesis</i> through a contrast with <i>graphesis</i> in terms of modes of expression, as well differences in attitudes about the foundations of knowledge in its creation, communication, and use (rather than in historical and philosophical misunderstandings about language). <i>Mathesis</i> is aligned with systems that privilege disambiguation, stable notation, and logical structures, as well as universal approaches to standard notation systems. <i>Graphesis</i> allows for ambiguity, instability, and rhetorical expressions and privileges the specificity of inscription. Graphical marks do not rely on difference for their value, but on specificity—the fact of each line or mark’s unique identity and quality. Even though they may be specified by algorithms, graphical lines are still “drawn” in digital environments. The implications of the differences between notational (mathematical) and inscriptional (graphical) practices (see below) leads to consideration of the underlying data structures and relations between these and graphical forms as well as of the visual expressions themselves.</p>
<p>Because digital technology operates in ways that are discrete and unambiguous at the level of the encoding and processing, it has often seemed to <span aria-label="27" id="pg_27" role="doc-pagebreak"/>be the fulfillment of the quest for <i>mathesis.</i> However, all symbolic systems, whether analogue or digital, can be put at the service of ambiguity and complexity at a higher level of representation. We can write nonsensical statements in a formal system quite easily, so long as the syntax of the formal expression conforms to the rules. We can use a line to draw a shape that defies meaning, even if it is stored unambiguously in an algorithm.</p>
<p>The distinction between <i>mathesis</i> and <i>graphesis</i> is not the same as the distinction between digital systems and analogue systems. The concept of <i>graphesis</i> draws on many principles of analogue forms of knowledge production which apply to digital inscriptions as well. One of the challenges for humanists wishing to create visualizations in digital environments that are adequate to the rhetorical and epistemological requirements of interpretation is to demonstrate the ability of computational systems to inscribe the specificity and particularity that are inherent features of visual knowledge production. Therefore, these features need to be identified and described and their role in knowledge production understood.</p>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Graphical specificity</samp></h3>
<p class="noindent">In his 1953 landmark study <i>Prints and Visual Communication</i>, William Ivins showed that engravings made possible the production of “exactly repeatable statements” in visual formats. He felt this made a contribution to the advancement of modern science.<sup><a href="chapter_1.xhtml#chapter1-36" id="chapter1_36" role="doc-noteref">36</a></sup> Beginning in the fifteenth century in Europe (and considerably earlier in Asia), printed images in scientific and technical publications created stable, repeatable, shared references, initially through woodcuts. The advantages of printed images were twofold. They could be circulated to create common understanding and visual reference, and they had particular graphical properties imposed by the technologies of the media in which the lines were produced and reproduced from wood and then metal. These supported the production of graphic information in what Nelson Goodman, in <i>Languages of Art</i> (1968), identified as either <i>allographic</i> or <i>autographic</i> modes (on which more below).<sup><a href="chapter_1.xhtml#chapter1-37" id="chapter1_37" role="doc-noteref">37</a></sup> The increased detail of line and tone afforded by copper and steel plates extended the graphic range—and consequently the authority—of images. Greater detail meant more information, and more information meant more accuracy and verisimilitude—in the same way, higher-resolution file formats are informationally richer than lower ones (though of course not always more accurate). Prints served to mediate scientific knowledge in every sense. They were <span aria-label="28" id="pg_28" role="doc-pagebreak"/>media, a means of inscription that embodied and communicated information in graphical codes. And they functioned to mediate—to serve as a site for focused, intersubjective exchange among professionals—contributing to the creation of a scientific community and consensus about the natural world and knowledge of it.</p>
<p>Ivins didn’t assume that a particular method of making (or technology of production) produced a particular response. He was not deterministic, but he did provide a way to read visual effects of media. The trained eye can read image structure, but also production history, by distinguishing different kinds of marks, lines, tonal values, color ranges, densities, textures, and patterns. The surface of a currency bill, for instance, with its raised ink lines left from an intaglio plate, has a graphical-tactile character that is essential to its operation (even in an era of embedded holograms and specially treated fibers). Visual translation from one medium to another always reveals the effects of transmission, the graphical code that literally inscribes knowledge. Ivins’s passionate dislike of the ultrarational technique of steel engraving was a dramatic instance of his attention to the affective power of image technology. He found the mechanistic dot and line patterns of the engraving roulette tool antithetical to aesthetic expression. Extreme cases always show the rule—the softening effects of paint on black velvet can render the most rigorous image kitsch, and the use of a medium can create cognitive dissonance simply by force of the rendering. An inventory of the various properties of graphical media does not supply a vocabulary of semantic values any more than dreams can be reduced to an inventory of symbols or styles in art to a particular set of brushstrokes, pigments, or even compositional methods. But in reading images as part of knowledge systems, Ivins’s approach offers a fundamental skill.<sup><a href="chapter_1.xhtml#chapter1-38" id="chapter1_38" role="doc-noteref">38</a></sup> We can read file formats with similar approaches in understanding what kinds of visual information they can record and how, and how in storing graphics in various ways, they embody models of epistemological understanding. The creation of an image as a vector graphic, a line drawing, a pixel tapestry, an RGB or a CMYK file has implications for precisely what information is constituted in its inscriptional trace. These technical and mechanical aspects of images provide a foundation on which the distinction between inscriptional (continuous value) and notational (discrete value) methods make sense—and on which the substantive differences in their functionality can be assessed.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><span aria-label="29" id="pg_29" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Notation and inscription</samp></h3>
<p class="noindent">Ren<span class="dcrit">é</span> Thom, the mathematician and philosopher, once wrote that “for a phenomenon to be an object of science, counted in the common (and, in principle, eternal) heritage of scientific knowledge, it is first necessary to describe it.”<sup><a href="chapter_1.xhtml#chapter1-39" id="chapter1_39" role="doc-noteref">39</a></sup> Then he noted that only two such descriptive techniques exist—“natural language and mathematical formalism.” He conspicuously excluded graphical description.<sup><a href="chapter_1.xhtml#chapter1-40" id="chapter1_40" role="doc-noteref">40</a></sup> Thom must have been aware of the substantial role visual images have played in producing and communicating knowledge in the history of the natural and physical sciences, but he considered graphical formats inadequate for accurate knowledge production and transmission.</p>
<p>But as we have seen, even before the existence of print technology, visual images served varied functions in connection with knowledge—from the representation of information in condensed, legible form, to the expression of complex states of mind and experience. Maps, graphs, diagrams, illustrations, pictorial images of all kinds, even handwriting and inscriptions, provide information through graphical means (as images) but also through their specific visual features (texture, syntax, color and other characteristics). Thom’s oversight, if it was an oversight, or decision, if it was deliberate, thus seems peculiar for so astute a thinker. His attitude is reminiscent of the denigration of vision in modern critical theory described by Martin Jay in <i>Downcast Eyes</i> (1993).<sup><a href="chapter_1.xhtml#chapter1-41" id="chapter1_41" role="doc-noteref">41</a></sup> As explanation, we can again invoke the long tradition of logocentrism that dominates western epistemology, even though, paradoxically, sight was always privileged in the hierarchy of the senses. From antiquity onward, the eye’s capability was associated with reason and enlightenment in ways that taste, touch, smell, and even hearing never were. Vision allowed perception at a distance, without direct contact or fleshly stimulation. But the promiscuity of images, their capacity to serve so many functions (entertainment, pleasurable distraction, communication), calls their knowledge bearing (epistemological) and moral status into question. Even recent critical studies admit that visual images are a less stable form of knowledge production than language. Large philosophical issues and deep-seated prejudices haunt us at every turn.</p>
<p>Something substantial had to have been underlying Thom’s pronouncement. Perhaps the main source of discomfort about visual images for any formal logician is that graphical signs are not stable in relation to their referents. Where a number can signify a quantity without ambiguity, an image is open to association and interpretation. Even showing the concept <span aria-label="30" id="pg_30" role="doc-pagebreak"/>of “two” in any graphical form, beside that of a number, creates suggestions and association. Two pies, two apples, two kittens—the “twoness” of these is difficult to separate from the other features of the images. Once the concept of “two” is extracted from the objects, however, it can be represented without difficulty with a numerical symbol. But with images, the problem extends to the level of the marks, the notation system. The basic code of numeric and alphabetic notation (and/or other written characters, such as Chinese, Japanese, or chemical symbols) is fixed and finite. Every letter or character can be distinguished unambiguously. Their combinations can be read, but more importantly, the components of written language can be disambiguated. Alphabetic signs do not have a comfortably fixed relation to morphemes or phonemes, and the same letters are used for a variety of languages, but they can be distinguished from each other. Their disambiguation at the level of signs is not a problem, even if their connection to various references may be complex and sometimes ambiguous.</p>
<p>Numerical codes are even more stable than linguistic ones, and at any level of combination or complexity, a numerical value and its sign remain in a stable relation. By contrast, a word and its meaning do not remain fixed, and the study of language has long concerned itself with the slippage of word and meaning, text and referent, value and use. But no equivalent to either alphabetic or numeric code exists in images. A line can be short or long, a dot can be round or misshapen. A stroke can be wide or thin, vary in width and weight. Where do the basic units of code begin and end? Of what does the basic visual system consist? Again, the answers to this question have generated a considerable literature.<sup><a href="chapter_1.xhtml#chapter1-42" id="chapter1_42" role="doc-noteref">42</a></sup> But no amount of analysis can resolve the unresolvable problem that, unlike language, images do not have a stable basic code.</p>
<p>Thom was right, therefore, to be anxious about graphicality, since it could not be relied on to be consistent in its execution (as a fixed set of notational signs) or its representation (in any stable relation to its references). A shift in size or weight could remake the value of a line and then change its meaning within an image in ways that could not be accounted for in any logical system. The resistance of graphicality to systematicity is one of its fundamental (epistemological) properties, but for Thom it was a fatal liability.</p>
<p>Because of his empirical disposition, Thom was concerned with notational systems, not inscriptional ones. The distinction is important for the arguments about the relation between visuality and epistemology. Both the contrast of <i>graphesis</i> and <i>mathesis</i> and the distinction between notation and <span aria-label="31" id="pg_31" role="doc-pagebreak"/>inscription are asymmetric, but are crucial to the discussion of the specific quality of graphical production and presentation of knowledge.</p>
<p>Goodman’s work, alluded to above, is a still-unsurpassed systematic study of visuality framed through a formal, analytic approach. Goodman’s definitions and analyses still hold, even if his focus did not address any of the dimensions that historical and ideological study bring to the understanding of images. His work was conceived under the influence of a modernist desire to create a complete understanding of “the language of form,” as if images were, like mathematics, subject to universal laws that worked outside of their temporal and cultural location.<sup><a href="chapter_1.xhtml#chapter1-43" id="chapter1_43" role="doc-noteref">43</a></sup> Goodman’s work still provides useful definitions and distinctions, such as the one he makes between autographic and allographic notation systems. The term autographic refers to those modes of inscription that cannot be transcribed without information loss. So, a signature is comprised of the particular loops and curves and muscle patterns that comprise it. Translating handwriting into a typewritten name or typographic rendering would take away vital information and authority that inheres in the signature (though digital signatures have eroded that particular aspect of functional distinction). Allographic systems, on the other hand, can be transcribed, remediated, and copied in another modality, or so Goodman believes, without losing their informational substance. They are notational rather than inscriptional. How far exactly the defense of allographic systems as invulnerable to information loss would go is worth considering. Take the example of a typewriter as an allographic system. Change its font into a typeface that has a distinctive character, such as Comic Sans or Old English Blackletter. Suddenly we realize that the idea of an allographic system is also problematic—information has been lost and gained in the translation, even though both fonts are allographic in Goodman’s sense. The specific properties of instantiation are not just embodied in the letter code, but in the inscriptional form of the characters. All graphical notation systems turn out to have some aspect of the autographic in them, no matter how minimal, and the loss of information that occurs in remediation is considerable. Whether it matters or not will depend upon the purpose to which the graphical image is being put. I would argue that truly allographic systems do not exist, for the reasons mentioned above. A system may be allographic at a formal level, as a notation system, but never at an inscriptional level where an image is produced as a material trace.</p>
<p><span aria-label="32" id="pg_32" role="doc-pagebreak"/>In <i>The Semiology of Graphics</i> (1967), Jacques Bertin outlined formal features of graphical systems from a different perspective.<sup><a href="chapter_1.xhtml#chapter1-44" id="chapter1_44" role="doc-noteref">44</a></sup> Bertin’s motivation was directly related to problems in cartography and the need to create a rational approach to the use of graphical features to communicate large amounts of information in a clear, legible way. He identified seven graphic variables—color, shape, tone, texture, orientation, position, and size—so that these could each be put to a distinct and deliberate purpose in mapmaking. Shape communicated semantic values, such as labels or types of information, more clearly than tone, which was better suited to comparison of intensities of value. His system was created to guide production of static graphics, not dynamic ones, and did not include any of the properties related to animated images, such as change over time, movement, growth, and so on. But the principles of his approach remain useful in design—as do those of many information designers from earlier generations whose manuals and/or examples are part of the inventory on which we draw.</p>
<p>With these thoughts about graphical knowledge in place, a few notes about the way visualization is used in computing might be useful in thinking about how the distinction between modeling interpretation and visualizing knowledge are directly linked to the challenge offered by <i>graphesis</i> to <i>mathesis</i>. What are the technical conditions and critical implications of modeling interpretation? Where and how are data structures to be created, stored, made flexible and iterative? What kind of information and knowledge are they able to encode? How can they remain sufficiently structured to function within the formal systems on which computation works while also inscribing hermeneutic specificity?</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Philosophical issues of imitation, mimesis, and simulation</samp></h3>
<p class="noindent">The development of digital image production intensified, rather than eliminated, philosophical debates about the epistemological stature of images.<sup><a href="chapter_1.xhtml#chapter1-45" id="chapter1_45" role="doc-noteref">45</a></sup> Questions about the epistemological identity of digital images were posed in terms of what their relation was to coded files—or simply, to code itself. Are digital images equivalent to their digital encoding? Or do all of the various processes of encoding, processing, and display need to be taken into account as forming a composite or aggregate identity? What, to put it bluntly, <i>is</i> a digital image? What constitutes it?</p>
<p>In forensic terms, as Matt Kirschenbaum has eloquently demonstrated, every digital trace is unique by virtue of its physical materiality.<sup><a href="chapter_1.xhtml#chapter1-46" id="chapter1_46" role="doc-noteref">46</a></sup> While on a <span aria-label="33" id="pg_33" role="doc-pagebreak"/>formal level, as a logical expression, a string of code can be repeated. But the instantiation of that code in a particular location on an actual digital device of any kind creates a specific trace that is unlike any other. The extent to which this uniqueness constitutes the epistemological identity of an image file may depend on whether an ontological question is being posed, or a pragmatic and operational one. Is a digital image, in its instantiation, unique and specific? Or is its potential for instantiation repeatable and/or iterative?</p>
<p>Hand-drawn images make truth claims based on verisimilitude (accuracy) and resemblance. A face drawn in an illustration program may resemble its source, but it does not bear any direct connection to that source except through comparison of visible features. Photographical images, however, base their claims on their production as direct traces of light. A scanner also creates a direct trace registering light in code. In either case, the file stores the information in a formal notation system, universal and context-independent, even if each inscription is distinguished from every other. But is the encoded file related to a display through an indexical chain? What ontological, or basic relation of identity, do the file and image have?</p>
<p>This contrast was noted in 1996 in an article by Hubertus von Amelunxen on digital photography. Amelunxen described two types of mimesis in digital images.<sup><a href="chapter_1.xhtml#chapter1-47" id="chapter1_47" role="doc-noteref">47</a></sup> He distinguished direct indexical traces (likeness/eikon) in traditional photography from the manufacture of images that follow codes of verisimilitude (simulacra). In a digital environment, both types of image exist. Photographically naturalistic works need not have a referent to pass as images of the “real.” But no matter what its source—camera eye, mouse, or software—at the point at which data is inscribed, it has a direct, specific authenticity as a forensic trace. The encoded trace has an ontological identity as a file.</p>
<p>In data display, an indexical link exists between the direct trace of light and its encoded record and also as a connection between code and display. None of these are equivalents. They are various iterations and remediated translations. This suggests that a claim can be made for the truth value of digital images as expressions of encoded data. The data and image are not one and the same—data can be given any number of graphical expressions, played as music, computed, rendered in color or black and white, and so forth. But the digital image is (popularly and fundamentally) conceived as a truth of another kind that is premised on a deep conviction about the relations of reason and truth, a rational link between mathematics and form, in which the <span aria-label="34" id="pg_34" role="doc-pagebreak"/>identity of a mathematical formula is supposed to exist irrefutably, absolutely, as an indispensable truth. This idea of truth in digital images seemed unsupportable then, and now. The truth invoked in a visual expression is not that of the data. In this positivist premise, the foundation of a digital ontology is linked to a belief that mathematical code storage is equal to itself, a truth that is based on identity irrespective of material embodiment. Once produced, data have a cultural authority that masquerades as an inherent (ontological) authority, pretending to an absolute self-identicality. When images such as visualizations are taken as equivalents to or for data, confusion arises.</p>
<p>Visualizations are not automatically generated from data. A single data set can be expressed in any number of graphical formats. These images stand in relation to the data as “Copy” does to “Idea” in a Platonic scheme. We might even argue that the visualization comes closer to Plato’s more debased category of the “Phantasm”—which is a copy of a copy—if we consider that the data are an abstraction from an original phenomenon.<sup><a href="chapter_1.xhtml#chapter1-48" id="chapter1_48" role="doc-noteref">48</a></sup> The fact that data, no matter how cleanly and formally they are encoded, have to be processed to generate a visualization, makes it impossible to assert any direct identification of code and image. These are (ontologically) distinct entities, linked in a relationship to each other that is indexical by virtue of its continuity and possibly iconic by virtue of the formal, logical structures encoded in digital files. Data and expression have a clear indexical link; they are not equal to each other.</p>
<p>In addition, in answer to the claims of “pure difference,” it should be noted that code has no ideality, no independent (or transcendental ontological) existence. Code is firmly, resolutely, and substantively material. The visual forms to which data give rise, its manifestation into substance, is what allows it to be available to perception and cognition. In a weak analogy to snowflakes, or some new age Heraclitan observation, it is fair to say that no two pixels are alike and that instantiation always bears in its material embodiment the specificity that makes for difference from the code—and from the data. In the visual practice of an information design, the assumption is that the information precedes the representation, that the information is other than the image and can be revealed by it, served by an accurate visual presentation. But form is <i>constitutive</i> of information, it is not merely its transparent presentation. The very acts of production and inscription, the scribing of lines of difference that create the specificity of an image, demonstrate the making of the form as an act of differentiation from <i>mathesis</i> (code). Furthermore, <span aria-label="35" id="pg_35" role="doc-pagebreak"/>code, however conceived, cannot be conceived as “pure” if purity suggests some independence from a material substrate or instantiation into material. Code is also, always, emphatically material, not pure.</p>
<p>However we conceive of the material inscription of digital information, in its logical and formal structure, it has an unambiguous character at the level of binary code. Rather than think of this as “pure difference,” the encoding should be thought of as materially dependent inscriptional specificity. This is not meant to suggest that code is self-identical, or that it has an “ideal” form to it as an expression of “truth” even at the level of inscription. Once expressed in graphical form, the highly discrete and particularized aspect of inscription guarantees its distinction in every instance. Another important point is that visualization does not depend upon the preexistence of code. From an early period of computer graphics, in Ivan Sutherland’s design of Sketchpad, we witness the demonstration of the direct production of code <i>from</i> image, of data <i>from</i> expression. This is significant, since the process of transferring information from a hand gesture to a screen to a file is always a mediation, with the attendant loss and modification of the information in the original inscribing act. No amount of computational power can fully record every nuance of difference in the pixels of the screen—for no two pixels are the same, and no pixel is the same as itself over time. In other words, digital displays are inscriptional by virtue of their material instantiation.</p>
<p>This discussion of the connection between digital images and their material instantiation leads to an examination of the specific properties of graphical inscription. The distinction between the formal system of code and the specificity of each instance of instantiation further raises questions of what constitutes the “information” to be encoded in either a direct production of a graphical production of knowledge or a remediation of a preexisting artifact and/or expression of a data set. If “form” is conceived in mathematical terms, essentially formal and logical, it can be understood in terms of a unity of essence and representation where conceptual value and expression are the same. But if “form” is conceived in terms of <i>graphesis</i>, then it resists this unity in part through the specificity imparted by material embodiment. This materiality cannot be fully absorbed into (or made one with) form as “pure code.”</p>
<p>The gap between the formal language of code and the particular, unique, specificity of any inscription marks the difference between the claims of <span aria-label="36" id="pg_36" role="doc-pagebreak"/><i>mathesis</i> (as universal and absolute) and those of <i>graphesis</i> (as located and infinitely varied). This distinction can be expanded into an argument for inscription as a fundamental aspect of <i>graphesis</i>. This situates any graphical act, whether generated from data as display or created directly on screen or in other media and materials, within cultural and social systems where the condition of materiality permits and/or requires critical considerations of the ways material form participates in and helps replicate cultural mythologies. In the case of digital images, this is a mythology in which code passes for truth, as if the easy and complete interchangeability of image into code and back into image is driven by a myth of the techno-superiority of mathematical premises. The idea of <i>graphesis</i> makes an argument against the concept of code as truth, by insisting on the distinction between <i>the form of information and information of form-in-material</i>. As a materially inscribed trace in a complex system of interrelated components, processes, and operations, code cannot escape its relation to <i>graphesis</i>. Code is always an inscription (an act of primary making) and inscriptional (characterized by the attributes of specificity and particularity forensically inherent in any trace).</p>
<p>This theoretical framework has been essential for establishing the fundamental identity (or ontology) of inscriptional forms within digital environments, and for making an argument for codes as inscriptional traces. But it does not provide any substantive description of the specific capacities of graphical forms to produce, instantiate, and communicate knowledge at a formal level. So let’s consider some of the ways graphical notation has been analyzed and its properties described.</p>
</section>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Visualization methods used in computing</samp></h2>
<p class="noindent">The previous discussion approached the status of digital images from a philosophical perspective, but the pragmatics of technical process must also be taken into account in any discussion of visualization. This aspect of the way knowledge and interpretation are produced occurs at the level of the workflow that creates what are commonly known as information visualizations. Computational techniques linking data and visual expressions constitute a specialized field. Its methods are created with specific uses in mind that shape the data and their display—and the relation between the two.</p>
<p>Standard visualization methods are performed from data through five distinct methods of algorithmic interpretation:</p>
<ol class="num">
<li class="NLF" value="1"><span aria-label="37" id="pg_37" role="doc-pagebreak"/><i>Description</i>: A descriptive presentation of already known data in a visual form allows patterns of large quantities of information to be seen and understood. The quantitative processing of massive amounts of information supports an exponential leap of qualitative judgment. The benefits of analysis and visualization are most evident at a large scale. (A problem like showing the comparative length of Shakespeare’s plays and the number of major and minor characters in each can be best understood through the compact presentation of information in a chart.) This is the standard graphics-expressed-as-metrics approach to visualization. It is pervasive, and so common that it is barely questioned. But this approach actually makes declarative statements from probabilistic models, that is, it is using <i>capta</i> (the products of a process of parameterization and modeling) as if they were <i>data</i> (preexisting entities). The longer lifecycle of data production is not visible, and the values expressed seem unproblematic.</li>
<li class="NL"><i>Analysis</i>: Analytic visualization allows for querying of data to see if it meets certain conditions, displaying those sets of information that conform to the limits (or parameters) of the query. Data, already present, can be analyzed and visualized. (For example, we could ask how many of Shakespeare’s works were written during any particular time period and how often they were performed.) This approach also uses graphic display as if it were a clear, reliable, unproblematic statement of data.</li>
<li class="NL"><i>Modeling</i>: In a radically different approach, modeling in visual form allows a hypothesis to be tested through visual means. Imagine, for instance, creating a model of a molecule, studying the resulting characteristics, and then putting another chemical substance into that configuration to see what properties it begins to exhibit. The same procedure could be performed on an aesthetic artifact by imitating formal features of meter, rhyme, narrative, semantics, or word frequency abstracted into a structure that is visualized and used to generate another work, etc. In this approach a higher-level formal structure embodied in a graphical expression is used as a template.</li>
<li class="NL"><i>Procedural approaches</i>: By contrast to the above modes, procedural visualization begins with an algorithm that generates form through a series of evolutions. (Process driven works of literature use such methods to create works from, for instance, vocabulary lists and rules for their <span aria-label="38" id="pg_38" role="doc-pagebreak"/>combination. Permutational and combinatoric works also fall into this category.) The graphic is generated directly from the process, or set of instructions, and used to read the outcome or result while concealing the procedures in the algorithm.</li>
<li class="NLL"><i>Emergence</i>: Finally, ways of making emergent models rely on developments and mutations that allow an algorithm to self-modify according to criteria of selection that simulate evolutionary models. (The rules of the procedure modify themselves so that not only the forms, but the terms on which they are created, continue to change.) These emergent models, such as those in agent-based and nonlinear systems, make use of the graphic display as a window into the unfolding process.</li>
</ol>
<p>These operations are used for data manipulation and can be applied to texts as generative and analytic processes. We could argue that each of these is, in fact, interpretative on account of the model underlying its operation, but only the third approach, modeling, allows a user to generate a graphical intervention for the purposes of creating an argument. To address that problem, we need to push further. In addition, we need to consider the critical understanding of these approaches. As most of these visualizations come about as the result of procedural, mechanistic approaches, we have to consider the way they participate in what we might term <i>the graphical imaginary,</i> the realm of ideological and cultural knowledge produced through these symbolic systems. Images produce values and/as knowledge, they combine concepts with ideologies, and never more so in the computational environments of current culture, with the heavy dependence on graphical formats in mediated communication cycles of everyday life.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Summary</samp></h2>
<p class="noindent">A basic (epistemological) distinction can be made between visual notation and inscription. On this basis, the specificity of inscription is understood to challenge generality. Unique instantiation pushes against formal systems that claim to operate in a context-independent manner. Understanding this is essential if visual methods are going to be used to serve interpretation and user-dependent knowledge production. The very specificity of inscription gives graphical forms their identity, fundamentally (ontologically) and materially (pragmatically), and makes them well-suited to assist <span aria-label="39" id="pg_39" role="doc-pagebreak"/>in the production of models of interpretation through graphical means, or as expressions of discursive, expressive forms that cannot be subsumed in formal, logical systems. This distinction brings us back to another basic issue—whether graphical forms are images <i>of</i> something, and thus stand in a secondary or surrogate relation to a preexisting form of knowledge, or whether they <i>create</i> knowledge in a primary sense. Because, in a digital environment, this question is often posed within assumptions about the character of code, insisting on the inscriptional trace is crucial.</p>
<p>In the rhetoric of cyber-speak, where data has somehow mistakenly come to carry an aura of immateriality as a feature of its fundamental identity, that identity has come to be conceived in a relation of identicality—of information to itself. Concepts of identicality—of something that presents a closed identity, as if it were in a stable and constant condition of being—are problematic from the perspective of the politics of representation. They lean toward totalization as a model of thought that leaves little or no room for the critical action and agency that are essential to any political basis for agency.</p>
<p>Central to the argument here is my conviction that an ideological agenda underpins the concept of self-identicality, as well as the cultural authority of formal, notational, systems. The specificity of graphical modes of expression presents an argument against the very possibility of such identicality and the truth claims it embodies. <i>Graphesis</i> can be positioned to challenge <i>mathesis</i> through a discussion of the ways the ontological identity of data visualization is generally conceived. In other words, in physical reality, nothing is ever the same as anything else—and may not even stay identical to itself moment to moment. Part of this assertion depends on a careful characterization of the way graphical expressions are instantiated in material.</p>
<p>Within the digital humanities, what is at stake in this discussion is very simply the question of <i>what kind of knowledge</i> we are engaged with in our work. The crucial epistemological issue in advocating visual, graphic expressions for interpretative work is based on the distinction between inscriptional specificity and notational generalizability. Specificity suggests a unique, even if non-self-identical, expression of an interpretative act. By definition, this is interpretative because it does not claim truth status as universal, repeatable, or independent of the circumstances of its production. Inscriptional expressions—whether analogue or digital—retain the trace of their conditions of production as part of their forensic identity. These conditions are embodied in the marks of their production and are thus able <span aria-label="40" id="pg_40" role="doc-pagebreak"/>to be read as indexical traces as well as contributing to the semantics and rhetorical force of argument and evidence. By contrast, the generalizable character of notational systems exempts them from these considerations. Notation functions as a user-independent means of encoding information, knowledge, experience, and so forth in a system that can be (ostensibly) decoded without regard for the specific qualities, or <i>qualia</i>, that are inscribed. In other words, an alphanumeric string can be used, copied, and remediated and still be functional; it does not have to be made or drawn in the same manner each time to remain useful.</p>
<p>If the humanities are attached to the notion of qualitative, subjective, located, and particularized expressions of knowledge as experience and evidence, then the recognition of the unique role of visual epistemology becomes clear—for the visual argues in its very expression and instantiation for the located particularity of human knowledge. In direct contrast (not opposition, but distinction) to user-independent knowledge, visual inscriptions argue for the specificity of user-dependent conditions of knowledge production as interpretative—where interpretation signals the subjective, located, inflected, and particular character of knowledge located within a subjective experience.</p>
<p>This argument is not meant to suggest that visual systems cannot be consensual, or that common experience cannot be communicated, or that standards and standardization cannot be expressed and achieved using visual means. All of these are well within the realm of visual epistemology. But they are not what distinguishes visual forms of knowledge from others. In a similar way, when dealing with sound recordings of speech, we note that the inflection of semantic value depends upon vocal expression as an inscriptional trace. This is inseparable from the conditions of production and reception. Gesture, voice, tone, style, and organization of print and layout, design and formal properties, all participate in the production of semantic value. They, too, are inscriptional in their character, not notational. They are specific, not general, particular not generic, and rooted in a user-dependent condition of production and reception, not independent of it. This locatedness requires attention and critical engagement in reading inscriptional materials.</p>
<p>Visual epistemology is distinct in the properties it brings into knowledge production—those of resemblance, iconicity, spatial arrangement, and so forth. But it also has properties that can be compared directly or by analogy <span aria-label="41" id="pg_41" role="doc-pagebreak"/>to those of hearing, such as tone, color, pattern, frequency, and order. The ability of the eye to make and register minute distinctions is remarkable, and much untapped potential to engage this capacity in graphical expressions can be pressed into the service of interpretative work. These can be far more nuanced and subtle than those in current use in visualization conventions.</p>
<p>No technical obstacle exists to recording, structuring, and making this kind of inscriptional work into data, and the challenge is merely one of sorting out what features of the visual are useful in creating arguments and interventions within the realm of digital projects and platforms. What matters is not what kind of epistemological contribution is made by visual means, but how visuality models knowledge, or epistemology, according to particular parameters of inscriptional specificity and notational generality.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Next</samp></h2>
<p class="noindent">Before turning our attention to critical interface design, nonrepresentational strategies, and a suite of projects in which these theoretical principles are embodied, we will pause to consider the fundamentals of critical hermeneutics recast in a performative and probabilistic mode. To fully explore the idea of <i>graphesis</i> as a means of producing interpretation, new knowledge from a subjective point of view, we need to extend the concept of knowledge, or epistemology, to include a probabilistic dimension. We have to go beyond thinking of knowledge in terms of mechanistic and static relations in which things known and things shown are assumed to be independent entities operating in an objective universe of phenomena existing in advance of their apperception. Visual epistemology is based on a theory of knowledge as a codependent production of subject and object in what Karen Barad has described as an <i>intra-action.</i><sup><a href="chapter_1.xhtml#chapter1-49" id="chapter1_49" role="doc-noteref">49</a></sup> This assumes two entities exist in relation to each other but are, crucially, also part of the same system. Their codependence cannot be disentangled. The process of interpretation that is at work in probabilistic hermeneutics draws on concepts of constructivist engagement that erodes subject-object distinctions. Now it is time to discuss these concepts in more detail and see how they relate to or are served by graphical expressions in a digital environment.</p>
</section>
<section epub:type="rearnotes" role="doc-endnotes">
<h1 class="BMH1"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Notes</samp></h1>
<ol class="footnotes">
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_1" id="chapter1-1">1</a></span>. See Sarah Worth, “Art and Epistemology,” <a href="https://www.iep.utm.edu/art-ep/">https://www.iep.utm.edu/art-ep/</a>, for evidence of this attitude and her arguments against it.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_2" id="chapter1-2">2</a></span>. The term <i>iconography</i> refers to the meaning of visual images, particularly in their work as symbols.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_3" id="chapter1-3">3</a></span>. Johanna Drucker, <i>Graphesis: Visual Forms of Knowledge Production</i> (Cambridge, MA: Harvard University Press, 2014).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_4" id="chapter1-4">4</a></span>. Richard Gregory, <i>Eye and Brain: The Psychology of Seeing</i> (Princeton: Princeton University Press, 1996), is a classic, as are Rudolf Arnheim’s, <i>Art and Visual Perception: A Psychology of the Creative Eye</i> (Berkeley: University of California Press, 1954) and <i>Visual Thinking</i> (London: Faber and Faber, 1969). See also Ernst Gombrich, <i>Art and Illusion</i> (Princeton: Princeton University Press, 1960).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_5" id="chapter1-5">5</a></span>. Peter S. Wells, <i>How Ancient Europeans Saw the World</i> (Princeton: Princeton University Press, 2012), provides an anthropological approach; but for image analysis from within this conception, see John P. Snyder, <i>Flattening the Earth</i> (Chicago: University of Chicago Press, 1993), W. J. T. Mitchell, <i>The Last Dinosaur Book</i> (Chicago: University of Chicago Press, 1998), and Martin Rudwick, <i>Scenes from Deep Time</i> (Chicago: University of Chicago Press, 1995).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_6" id="chapter1-6">6</a></span>. Harry N. Robin, <i>The Scientific Image: From Cave to Computer</i> (New York: Harry N. Abrams, 1992), is one good source for a treatment that includes analysis of the scientific issues in the images and their contribution. See also Michael E. Lynch and Steve Woolgar, eds., <i>Representation in Scientific Practice</i> (Cambridge, MA: MIT Press, 1990).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_7" id="chapter1-7">7</a></span>. Wilfrid Blunt, with William T. Stearn, <i>The Art of Botanical Illustration: An Illustrated History</i> (London: Collins, 1950); Tim Lenoir, ed., <i>Inscribing Science: Scientific Texts and the Materiality of Communication</i> (Stanford: Stanford University Press, 1998); Lorraine Daston and Katharine Park, <i>Wonders and the Order of Nature 1150–1750</i> (New York: Zone Books, 2001); Bruno Latour, “Visualization and Cognition: Drawing Things Together,” <i>Knowledge and Society</i> 6 (1986), 1–40; Karin Knorr-Cetina, <i>Epistemic Cultures: How the Sciences Make Knowledge</i> (Cambridge, MA: Harvard University Press, 1999); Alina Payne, ed., <i>Vision and Its Instruments</i> (College Park: Penn State University Press, 2014); David Freedberg, <i>Eye of the Lynx: Galileo, His Friends, and the Beginnings of Modern Natural History</i> (Chicago: University of Chicago Press, 2002).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_8" id="chapter1-8">8</a></span>. Daniel Simons and Christopher Chabris created the original video to test “selective attention” in <a href="https://www.youtube.com/watch?v=vJG698U2Mvo">https://www.youtube.com/watch?v=vJG698U2Mvo</a>; see also their jointly authored article, “Gorillas in Our Midst: Sustained Inattentional Blindness for Dynamic Events,” <i>Perception</i> 28 (1999), 1059–1074.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_9" id="chapter1-9">9</a></span>. Gombrich, <i>Art and Illusion</i>.</p></li>
<li role="doc-endnote"><p class="endnote"><span aria-label="180" id="pg_180" role="doc-pagebreak"/><span class="en_tx"><a href="chapter_1.xhtml#chapter1_10" id="chapter1-10">10</a></span>. J. J. Gibson, <i>The Ecological Approach to Visual Perception</i> (Boston: Houghton Mifflin, 1986).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_11" id="chapter1-11">11</a></span>. Jerome Lettvin, Humberto Maturana, Warren McCulloch, and Walter Pitts, “What the Frog’s Eye Tells the Frog’s Brain,” <i>Proceedings of the IRE</i> 47, no. 11 (1959), is a much-cited and debated paper about “feature detectors” in the visual system.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_12" id="chapter1-12">12</a></span>. Claudia Swan, “Illustrated Natural History,” in Susan Dackerman, ed., <i>Prints and the Pursuit of Knowledge in Early Modern Europe</i> (Cambridge, MA: Harvard University Press, 2011).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_13" id="chapter1-13">13</a></span>. Anton Stankowski, <i>The Visual Presentation of Invisible Processes: How to Illustrate Invisible Processes in Graphic Design</i> (New York: Hastings House, 1964).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_14" id="chapter1-14">14</a></span>. Peter Galison, <i>Image and Logic: A Material Culture of Microphysics</i> (Chicago: Chicago University Press, 1997).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_15" id="chapter1-15">15</a></span>. Eugene Ferguson, <i>Engineering and the Mind’s Eye</i> (Cambridge, MA: MIT Press, 1992).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_16" id="chapter1-16">16</a></span>. Denise Schmandt-Besserat, <i>How Writing Came About</i> (Austin: University of Texas Press, 1992), contains a discussion of the relations between ground lines, writing, and images.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_17" id="chapter1-17">17</a></span>. I would be willing to make the case for any image on these terms—abstract formalism in the mode of Kandinsky, Ad Reinhardt, or Agnes Martin, collage and pastiche work, portraits and landscapes, small studies, vignettes, conceptual, procedural, and thematic work. Every image contains a presumption about the relation between vision and knowledge, perception and its social and cultural location and construction, and the contract between viewer and producer of the work.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_18" id="chapter1-18">18</a></span>. The portrait being referenced is currently in the Staatliche Museen at Kassel</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_19" id="chapter1-19">19</a></span>. Rembrandt’s evident preoccupation with this issue is evident in the nearly one hundred self-portraits he produced, with their varied answers to this question. Taken as a proposition, how can the subject know itself as an object, the formulation of self-portraiture is a continual investigation of the spectrum of beliefs according to which it can be answered.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_20" id="chapter1-20">20</a></span>. Self-portraits are interesting in this regard, since they play with conventions of objectivity as well as positions of subjectivity across a wide range of conventions. Think of D<span class="dcrit">ü</span>rer’s self-presentation as a religious icon, or Klimt’s as a figure of abjection.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_21" id="chapter1-21">21</a></span>. For the notion of “pure difference,” see Adam Nash, “An Aesthetics of Digital Virtual Environments,” in Denise Doyle, ed., <i>New Opportunities for Artistic Practice in Virtual Worlds</i> (Hershey, PA: IGI Global, 2015), 7.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_22" id="chapter1-22">22</a></span>. Garfield Benjamin, “‘Virtual Reality’ Reconsidered,” in Drew Harrison, ed., <i>Handbook of Research on Digital Media and Creative Technologies</i> (Hershey, PA: IGI Global, 2015), 216.</p></li>
<li role="doc-endnote"><p class="endnote"><span aria-label="181" id="pg_181" role="doc-pagebreak"/><span class="en_tx"><a href="chapter_1.xhtml#chapter1_23" id="chapter1-23">23</a></span>. Michael Eldred, “Digital Dissolution of Being,” in <i>The Digital Cast of Being</i> (Frankfurt: Ontos Verlag, 2009), 2, <a href="https://www.scribd.com/document/59553025/Digital-Dissolution-of-Being">https://www.scribd.com/document/59553025/Digital-Dissolution-of-Being</a>; see also Charlie Gere, “Digital Art and Visual Culture,” in Ian Heywood and Barry Sandywell, eds., <i>The Handbook of Visual Culture</i> (London: Berg, 2012), 566: “In that it has no material existence and is based on pure difference the ‘digital’ is something like Derrida’s Chora.”</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_24" id="chapter1-24">24</a></span>. Alain Badiou, “The Ontology of Multiplicity: The Singleton of the Void” (2011), <a href="http://www.arasite.org/badiou2011a.html">http://www.arasite.org/badiou2011a.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_25" id="chapter1-25">25</a></span>. Johanna Drucker, “Digital Ontologies: The Ideality of Form in/and Code Storage—or—Can Graphesis Challenge Mathesis?,” <i>Leonardo</i> 34, no. 2 (2001), 141.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_26" id="chapter1-26">26</a></span>. Ibid.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_27" id="chapter1-27">27</a></span>. Leibniz: “I thought again about my early plan of a new language or writing-system of reason, which could serve as a communication tool for all different nations” (cited by Dalakov, from a note, <a href="http://history-computer.com/Dreamers/Leibniz.html">http://history-computer.com/Dreamers/Leibniz.html</a>), and also “in his February, 1678, essay ‘Lingua Generalis,’ <span class="ellipsis">…</span> connected closely with his binary calculus ideas[,] Leibniz spoke for his <i>lingua generalis</i> or <i>lingua universalis</i> as a universal language, aiming it as a lexicon of characters upon which the user might perform calculations that would yield true propositions automatically, and as a side-effect developing binary calculus” (ibid.).</p></li>
</ol>
<p class="TX1">“The only text in which Descartes explicitly mentions the expression <i>mathesis universalis</i> is in a passage from the <i>Rules for the Direction of the Mind</i>, where it is described as a ‘general science that explains everything that it is possible to inquire into concerning order and measure, without restriction to any particular subject-matter.’” Fr<span class="dcrit">é</span>d<span class="dcrit">é</span>ric de Buzon, “Mathesis Universalis,” in Lawrence Nolan, ed., <i>The Cambridge Descartes Lexicon</i> (Cambridge: Cambridge University Press, 2015), <a href="https://doi.org/10.1017/CBO9780511894695.166">https://doi.org/10.1017/CBO9780511894695.166</a>. The term does not show up anywhere else in Descartes, according to de Buzon.</p>
<p class="TX1">See also J. Mittlestrass, “The Philosopher’s Conception of <i>Mathesis Universalis</i> from Descartes to Leibniz,” <i>Annals of Science</i> 36, no. 6 (1979), 563–610, <a href="https://www.tandfonline.com/doi/abs/10.1080/00033797900200401">https://www.tandfonline.com/doi/abs/10.1080/00033797900200401</a>.</p>
<ol class="footnotes">
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_28" id="chapter1-28">28</a></span>. James Knowlson, <i>Universal Language Schemes in England and France 1600–1800</i> (Toronto: University of Toronto Press, 1975), as a start point.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_29" id="chapter1-29">29</a></span>. Bishop John Wilkins, <i>An Essay Towards a Real Character, and a Philosophical Language</i> (London: Printed by John Martin for the Royal Society, 1668).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_30" id="chapter1-30">30</a></span>. Erik Iversen, <i>The Myth of Egypt and Its Hieroglyphs in European Tradition</i> (Princeton: Princeton University Press, 1993).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_31" id="chapter1-31">31</a></span>. Ernest Fenollosa and Ezra Pound, <i>The Chinese Written Character as a Medium for Poetry: A Critical Edition</i>, ed. Haun Saussy, Jonathan Stalling, and Lucas Klein (New York: Fordham University Press, 2008). The essay was originally published in 1919 <span aria-label="182" id="pg_182" role="doc-pagebreak"/>and in spite of its inaccuracies had a great impact on modern poetry and Imagism in particular.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_32" id="chapter1-32">32</a></span>. George Boole, <i>An Investigation into the Laws of Thought</i> (London: Walton and Maberley, 1854), and Ramon Cirera, ed., <i>Carnap and the Vienna Circle: Empiricism and Logical Syntax</i> (Amsterdam: Rodopi, 1994).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_33" id="chapter1-33">33</a></span>. Norbert Wiener, <i>Cybernetics: or, Control and Communication in the Animal and the Machine</i>, 2nd ed. (1948; Cambridge, MA: MIT Press, 1961).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_34" id="chapter1-34">34</a></span>. John Searle, “Cognitive Science and the Computer Metaphor,” in B. G<span class="dcrit">ö</span>ranzon and Magnus Florin, eds., <i>Artificial Intelligence, Culture, and Language: On Education and Work</i> (Berlin-Heidelberg: Springer, 1990), 23–34, <a href="https://link.springer.com/chapter/10.1007/978-1-4471-1729-2_4">https://link.springer.com/chapter/10.1007/978-1-4471-1729-2_4</a>; Hubert Dreyfus, <i>What Computers Can’t Do: The Limits of Artificial Intelligence</i> (New York: Harper and Row, 1972). See also work on the debates, Teodor Negru, “Intentionality and Background: Searle and Dreyfus against Classical AI Theory,” <i>Filosofia Unisinos</i> 14, no. 1 (2013), <a href="http://revistas.unisinos.br/index.php/filosofia/article/view/fsu.2013.141.02">http://revistas.unisinos.br/index.php/filosofia/article/view/fsu.2013.141.02</a>; and Lee Gomes, “When Computers Are Not Really ‘Brains,’” <i>Forbes</i>, April 23, 2009, <a href="https://www.forbes.com/forbes/2009/0511/046-artificial-intelligence-neuroscience-digital-tools.html#4f64ee46b455">https://www.forbes.com/forbes/2009/0511/046-artificial-intelligence-neuroscience-digital-tools.html#4f64ee46b455</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_35" id="chapter1-35">35</a></span>. John Searle, “Can Computers Think?,” in <i>Minds, Brains, and Science</i> (Cambridge, MA: Harvard University Press, 1983), 28–41.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_36" id="chapter1-36">36</a></span>. William Ivins, Jr., <i>Prints and Visual Communication</i> (Cambridge, MA: Harvard University Press, 1953).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_37" id="chapter1-37">37</a></span>. Nelson Goodman, <i>Languages of Art: An Approach to a Theory of Symbols</i> (Indianapolis: Bobbs-Merrill, 1968).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_38" id="chapter1-38">38</a></span>. Estelle Jussim, <i>Visual Communication and the Graphic Arts</i> (New York: R. R. Bowker, 1974); the reference work of Bamber Gascoigne, <i>How to Identify Prints: A Complete Guide to Manual and Mechanical Processes from Woodcut to Inkjet</i> (London: Thames and Hudson, 1986); and also the extremely valuable Graphics Atlas at Rochester Institute of Technology, <a href="http://www.graphicsatlas.org/">http://www.graphicsatlas.org/</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_39" id="chapter1-39">39</a></span>. Ren<span class="dcrit">é</span> Thom, “Stop Chance! Stop Noise!,” <i>SubStance</i>, no. 40 (1982), 9–21, special issue on OuLiPo.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_40" id="chapter1-40">40</a></span>. Drucker, <i>Graphesis</i>, 23, contains another version of this argument and citation. Other references to Thom that foreshadow the version here follow on pp. 24–25. An early version of some of these arguments appeared as “Graphesis” in <i>PAJ (Poetess Archive Journal)</i>, special issue, “Visualizing the Archive,” March 2011, <a href="http://tei-l.970651.n3.nabble.com/Visualizing-the-Archive-td2657423.html">http://tei-l.970651.n3.nabble.com/Visualizing-the-Archive-td2657423.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_41" id="chapter1-41">41</a></span>. Martin Jay, <i>Downcast Eyes</i> (Berkeley: University of California Press, 1993).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_42" id="chapter1-42">42</a></span>. The attention of structuralist critics and semioticians produced an exhaustive study of these issues and contrasts, beginning with Roman Jakobson, “On Some <span aria-label="183" id="pg_183" role="doc-pagebreak"/>differences,” and proceeding through the work of Norman Bryson, Umberto Eco, Mieke Bal, Roland Barthes, and numerous others.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_43" id="chapter1-43">43</a></span>. See Drucker, <i>Graphesis</i>, for a long discussion of these formal approaches within late nineteenth-century and twentieth-century modernism.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_44" id="chapter1-44">44</a></span>. Jacques Bertin, <i>The Semiology of Graphics: Diagrams, Networks, Maps</i> (Madison: University of Wisconsin Press, 1983), originally published in French in 1967 as <i>Sémiologie graphique</i> (The Hague: Mouton; Paris: Gauthier-Villars, 1967).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_45" id="chapter1-45">45</a></span>. This section of the chapter draws on material from Drucker, “Digital Ontologies,” 141–145.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_46" id="chapter1-46">46</a></span>. Matthew Kirschenbaum, <i>Mechanisms: New Media and the Forensic Imagination</i> (Cambridge, MA: MIT Press, 2008), especially chapter 1, “Every Contact Leaves a Trace.”</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_47" id="chapter1-47">47</a></span>. Hubertus von Amelunxen, Stefan Iglhaut, Florian R<span class="dcrit">ö</span>tzer, et al., eds., <i>Photography after Photography: Memory and Representation in the Digital Age</i> (Amsterdam: G+B Arts, 1996).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_48" id="chapter1-48">48</a></span>. In Drucker, “Digital Ontologies,” this part of the discussion focused on photographic images, not data representations, as well as on images generated from algorithms, such as the early pioneering work of Jack Citron and George Nees from the 1970s.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_1.xhtml#chapter1_49" id="chapter1-49">49</a></span>. Karen Barad, <i>Meeting the Universe Halfway: Quantum Physics and the Entanglement of Matter and Meaning</i> (Durham: Duke University Press, 2007).</p></li>
</ol>
</section>
</section>
</div>
</body>
</html>