<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en">
<head>
<title>3 Graphic Arguments: Nonrepresentational Approaches to Modeling Interpretation</title>
<meta content="text/html; charset=utf-8" http-equiv="default-style"/>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:ab716dc3-7c3d-4fc9-9c55-4cc6a0edf9ef" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter">
<div class="body">
<p class="sp"> </p>
<section aria-labelledby="ch3" epub:type="chapter" role="doc-chapter">
<header>
<h1 class="chapter-title" id="ch3"><span aria-label="69" id="pg_69" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">3</samp>    <samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Graphic Arguments: Nonrepresentational Approaches to Modeling Interpretation</samp></h1>
</header>
<p class="noindent">Arguments about nonrepresentational approaches to graphic activity weave throughout this book for a reason. The term <i>nonrepresentational</i> is not meant to suggest that a work is not visual, but instead, to suggest that it is a graphic made as a primary act of knowledge production. Nonrepresentational images are ones that do not serve as surrogates for an already existing object, whether that object is a thing, a place, an experience in the world, or a data set. In this context, the term nonrepresentational emphasizes the constructed character of knowledge production as interpretation. Though there is no barrier to creating nonrepresentational graphics from an empirical or positivist perspective, the use of the term within Nigel Thrift’s work in geography (which I take as my source) was meant to emphasize experiential models of space presentation. These were counterposed to conventions of mapping that assumed space as a given, with a map as its surrogate, in a stable, largely unproblematic relation between the two.</p>
<p>Understanding the distinction between visualization and modeling here is essential. Information design is a subset of graphic design. In the words of one the foremost practitioners of visualization, Edward Tufte, the task of the information designer is to “show the data” and to “avoid distorting what the data have to say.”<sup><a href="chapter_3.xhtml#chapter3-1" id="chapter3_1" role="doc-noteref">1</a></sup> Tufte also goes on to say, “Graphics reveal data.” Tufte’s conviction that information exists independent of—or in advance of—the presentation of data in graphical form is problematic. A spread sheet may hold “data,” but his idea is that the data have a “form” that can be “revealed.” On a pragmatic level, information designers understand their task as the creation of clear, legible, unambiguous presentations of this data. They see “data” as quantitative values stored in an analogue or digital format and the role of the visualization is to show patterns in this information. But every graphic representation is also a rhetorical device. <span aria-label="70" id="pg_70" role="doc-pagebreak"/>Every presentation structures arguments—it doesn’t simply “reveal” facts, or forms, in all their purity. The relations between <i>what</i> is communicated and <i>how</i> have to be acknowledged. A spread sheet is an embodied format. It has particular graphical properties that structure our reading of the values it holds. Even such a basic visual format can be understood as an argument structure that communicates through graphical organization.</p>
<p>Formats are semantic by virtue of their structure. The column and row organization of a spread sheet produces meaningful relations. Charts and graphs carry values through labelling, data storage, and sometimes imagery that links them to specific domains. The conventions for visual display of knowledge are <i>performative</i> (they make and generate knowledge) and <i>representational</i> (they can be put at the service of display of apparently preexisting knowledge derived from a table, chart, or text or embodied in an object in the world).</p>
<p>The inventory of types of visual information structures isn’t long: bar diagrams, trees, maps, pictorial diagrams and icons, flow charts, bubble charts, and tables. Taking each of these in turn we see that:</p>
<ul class="bull">
<li class="BLF">Bar diagrams derive from statistical analysis and function through supposedly unambiguous distinctions expressed in a grid of rationalized information readily available for comparison according to a standard metric.</li>
<li class="BL">Tree structures, by contrast, derive from genealogy and evolutionary biology and suggest continuity of dependence and kinship in the flow of information across generations.</li>
<li class="BL">Maps are the record of explorations, phatic and tactile, narrative and immersive when created from inside the experience of discovery, but rationalized through projection when produced from outside, as images. The complexities of representing a curved form on a flat surface, as well as the many cultural imperialisms at work, provide their own history within the range of projection methods.</li>
<li class="BL">Pictorial diagrams that make use of icons and other images have a cultural specificity through their particular details, the way they are rendered, as well as the inventory of images used (to show a woman, for instance). Pictorial images carry and evoke multiple associations.</li>
<li class="BL">Flow charts have their origins in management and organizational structures. The directional force of power relations and movement of goods through a production system often has a conspicuous absence of human agents, as if processes were an inevitable and natural fact.</li>
<li class="BL"><span aria-label="71" id="pg_71" role="doc-pagebreak"/>Tables and grids work by putting discrete cells of information into meaningful syntactic relations with each other—a classic example is the timetable.</li>
<li class="BLL">Network diagrams assume an absolute distinction between nodes and the edges that connect them, and their display is organized by algorithms that optimize display rather than following strict interpretation of the relationships among the nodes. Their visual arrangement cannot be read as an accurate presentation of information, only an approximation.</li>
</ul>
<p class="TNI2">These forms are usually displayed on a single, unified and rationalized surface—page or screen. The vocabulary of charts and graphs provides only a very elementary starter set of graphic forms structured on linear, hierarchical, and tabular models. More complex spatialized and temporalized relations can also be described through topological (mathematical) approaches that maintain basic logical relationships in spite of distortions and changes in scale. Topology emerged from the eighteenth-century mathematician Leonhard Euler’s struggles with the K<span class="dcrit">ö</span>nigsberg Bridge problem. In 1736 Euler established what he called a “geometry of position, not of measure” as a foundational principle.<sup><a href="chapter_3.xhtml#chapter3-2" id="chapter3_2" role="doc-noteref">2</a></sup> Johann Benedict Listing, in 1847, was the first to use the word topology to discuss the connectivity of surfaces.<sup><a href="chapter_3.xhtml#chapter3-3" id="chapter3_3" role="doc-noteref">3</a></sup> While used in modeling events in chaos and complexity, topological models have rarely been put in service to humanistic interpretation or its presentation in graphical form. Given the complex systems involved in narrative, discourse analysis, and event structures, it would make sense to make more use of these and other mathematically sophisticated models.</p>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Graphical input</samp></h2>
<p class="noindent">When Ivan Sutherland created Sketchpad in 1963, he engineered a system of direct graphical input from user manipulation on the screen to data storage.<sup><a href="chapter_3.xhtml#chapter3-4" id="chapter3_4" role="doc-noteref">4</a></sup> The images he created were not based on data, or even on formulae or algorithms, but created as free expressions of his light pen registering in pixels. Interestingly, the system was designed to store the information as a topological form, keeping the logical structure of the graphic intact in spite of morphs or changes in size, scale, position, or orientation.<sup><a href="chapter_3.xhtml#chapter3-5" id="chapter3_5" role="doc-noteref">5</a></sup> This approach to visual information lacks the precision and specificity of inscriptional approaches, but still demonstrates the primary point—that images can <i>create data sets and structures</i> rather than simply <i>express them</i>. <span aria-label="72" id="pg_72" role="doc-pagebreak"/>To relate the technique of graphical expression to scholarly interpretation requires thinking about the basic components of concept modeling (a term used in data design to indicate a way of making a model of an idea, field, or problem) through visual means. What are the semantics of graphics, and how can argument structures be made legible through visible methods?</p>
<p>In the sciences, visual modeling techniques are frequently used as a way to test a thesis or create new knowledge through experiments that bring an idea into form. Visual modeling techniques and procedures are rarely used in humanistic approaches to interpretation. In part this is because our work tends to be text-based, and determining what is to be “quantized” in a text is sometimes difficult. The rise of information design and increased familiarity with display techniques as part of computational analysis in digital humanities has softened the resistance to visual presentation of data. But approaches to interpretation that use visual modeling as a primary method of analysis—to create the data (especially structured data), not just display it—are less familiar. If a narrative structure involves multiple figures and agents, it will need to be charted in ways that involve emergent properties, not merely linear chartings of its events. The intuitions that govern interpretation are not governed by mathematical systems, but their graphical expression can be processed into a data structure.</p>
<p>How can we understand the relation of representation and model? All visual images are expressions of models, if by model we mean an abstract, schematic structure that expresses a concept—but not all visual images are <i>only</i> models. Many are representational, or decorative, or contain all kinds of accidental and incidental information. Representations appear to be self-evident, but we can qualify this by showing that a representation is a special type of model. Representations exhibit different degrees of isomorphic (structural) connection between the visual image and its referent. Charles Peirce’s categories of icon, index, and symbol define three basic relations of resemblance, continuity, and arbitrariness. But even the most visually analogous image (e.g., a realistic rendering of a frog) is an expression of a model (in this case, it expresses the concept of visual analogy and isomorphism or structural similarity).</p>
<p>Even the earliest graphical expressions of human activity demonstrate basic principles that remain operative in current forms. A Neolithic calendar found in Bulgaria and dated to the 4th or 5th millennium BCE uses a grid to organize the marks tracking the phases of the moon.<sup><a href="chapter_3.xhtml#chapter3-6" id="chapter3_6" role="doc-noteref">6</a></sup> A high degree <span aria-label="73" id="pg_73" role="doc-pagebreak"/>of abstraction is required to create a structured system to conceive of temporal events in such elaborate relations. Calendars are visual forms designed for use, not just static display like, say, religious icons. Calendars are surfaces organized to put temporal units into relations with each other in a very specific way. The surface has been rationalized, organized by a system of coordinates that structures information so that we read it relationally. But in fact, the abstract structure isn’t a representation of time, it is a model of time that allows for calculation or computation. The structure and the information are not identical with each other. The calendar models temporal elements so they can be manipulated and managed (organized into days, weeks, and months with repeating patterns). It doesn’t just represent some “natural” condition of time. By providing an idea of the way time is structured, it embodies this in the graphical presentation, but the schematic abstraction allows different combinatory possibilities to be produced. The calendar grid suggests that the days have both an ordered sequence and are part of grouped and repeating events—ideas that are readily apparent in the visible evidence. Similar abstract capabilities are evident in the tokens devised in the earliest counting and accounting systems. The principles that organize cuneiform writing in the 3rd millennium BCE make use of numbers, symbols, and word representations simultaneously. A mark doesn’t represent some <i>thing</i> in such a system, it represents an instance of a type of thing within categories. The classification system for this might not be rendered explicit, but it is nonetheless fully operative, and legible, in the graphical code.</p>
<p>The distinction between model and representation allows for self-consciousness about the rhetoric of graphical expressions. Unlike representations (which are surrogates), models have the capacity to generate new intellectual insight, not simply represent what is already known in a graphical form. A bit more clarification of the basic distinction between the idea of modeling knowledge and representing it may be useful. Representations are always premised on abstract conceptual schemes—or models—that shape any individual expression within constraints and patterns of thought. But a representation is not a model, it is an image that embodies a model or models but gives them a specific expression. Though our ideas of what something should be—a house, an airplane, an automobile—constrains our ability to design these things within an abstract model, once we make the house or plane, it is also an expression of a model. Breakthroughs in knowledge come from changing the model, or by innovative expressions. <span aria-label="74" id="pg_74" role="doc-pagebreak"/>Changing uses of computer-aided design have signaled a shift in attitudes toward architecture and the manipulation of forms through abstract, graphic processes. Of course, a change in a representation—making a three-legged frog or a monkey with antennae—might call forth a new model, but it is still serving as a re-presentation of that visual form or idea.</p>
<p>As already noted, the term nonrepresentational does not mean that the approach contains no graphic features. Quite the contrary, nonrepresentational approaches use graphical means as a primary method of modeling human-authored interpretation rather than displaying preexisting data sets, as we shall see.</p>
<p>If I draw a line, a single line, on a piece of paper, across a bit of territory, between members of a group, it divides one area of paper, space, group, and gathering from another. The line does not <i>represent</i> a division, it <i>performs</i> that division. Neither the identity nor the function of that line has anything to do with imitation. The line does not resemble anything beyond itself. It does not stand for something else, even if it can carry all kinds of values and resonances and become a border, an edge, a defining demarcation of exclusion. The line is the quintessence of a performative graphic expression. The line is visual—sketched, etched, drawn, or merely traced—it is palpable and tractable as a line, as a graphical trace, an expression, a thing that has dimension, duration, extension, all the properties of form. It signifies first by virtue of having been drawn. The coming into existence of the line performs its primary work. But it gathers signification, or meaning value, through the resonant features of its place and position, the conditions within which it registers as a line, and by the attributes it carries—thin, thick, clean, rough, straight, mechanical, etc. The list of attributes can be extended infinitely, and they may carry and/or call forth meaning through associations. But the primary act of making a line as a single inscription is fundamentally and profoundly nonmimetic. The drawing of the line is performative. All nonrepresentational graphical expressions are performative and nonmimetic in the same sense. They are generative. They are primary means of creating signification through graphical methods and expressions. Even if they “look like” something else, they were generated first and then assumed their air of resemblance afterward. The importance of this for modeling interpretation cannot be overstated.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><span aria-label="75" id="pg_75" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Rationale for nonrepresentational approaches</samp></h2>
<p class="noindent">This section presents an epistemological rationale, intellectual justification, and design outline for a nonrepresentational approach to modeling interpretation in a graphical environment.<sup><a href="chapter_3.xhtml#chapter3-7" id="chapter3_7" role="doc-noteref">7</a></sup> It begins with a critical discussion of the representational approaches that are the common form of information visualizations and suggests that the less familiar nonrepresentational approach could be used to augment these existing visualizations by supporting interpretative work that is closer to the practice of humanistic hermeneutic traditions. Representational display, based on large-scale processing, surrogates, and conventional visualizations, and nonrepresentational modeling at the level of the individual interpretative act operate at very different scales and support distinct intellectual work. In a representational approach, data precede display. Display is a surrogate produced according to automated protocols and algorithms. These cannot be altered or intervened except through rewriting their code, and the display, though interpretative and subject to interpretation, cannot be used as a means by which interpretation is actually modeled. While all visualizations express a model, they do not all provide a modeling environment. In the nonrepresentational approach proposed here, graphical input serves as a primary means of interpretative work. More significantly, a graphical environment that supports direct modeling of interpretation allows traditional humanistic approaches, close reading and marking of texts, documents, artifacts, or images to be integrated with computationally produced visualizations.</p>
<p>While information visualization has become ubiquitous in digital humanities, common tools for graphic expressions of data have limited value as primary modes of creating interpretation. They do not provide an environment in which interpretation is actually done directly. The traditional work of scholarly interpretation, at the level of individual artifact or text, often seems at odds with the computational processing that produces data visualizations. An alternative, grounded in a nonrepresentational approach to modeling interpretation in a graphical environment, could add essential capacity to the existing methods and platforms by providing a space for direct creation and inscription of interpretative work.</p>
<p>User-authored interpretation is premised on the distinction between display and modeling and signals a crucial difference between the two approaches. The modeling approach uses graphical means to produce <span aria-label="76" id="pg_76" role="doc-pagebreak"/>interpretative work using visual argument structures such as contradiction, ambiguity, parallax, and point of view that are fundamentally interpretative in character. It engages conventions and dimensions of graphicality not used in standard chart, graph, timeline, and mapping software with their entities and attributes. The system I developed in the context of the 3DH project at the University of Hamburg is meant to be a radically innovative addition to existing visualizations and to add new dimensions in the service of interpretation and modeling alongside representation and display. The term <i>modeling</i> is being used here to refer to the process of creating a generalized intellectual schema or structure and should not be confused with the way the word is used to refer to three-dimensional rendering software.<sup><a href="chapter_3.xhtml#chapter3-8" id="chapter3_8" role="doc-noteref">8</a></sup></p>
<p>As noted here repeatedly, the visualizations adopted by digital humanists (charts, graphs, diagrams, maps, and timelines) were mainly developed in the natural sciences, social sciences, statistics, business applications, and other fields. These bear the hallmarks of positivist, quantitative and/or statistical approaches to knowledge that limit their application to interpretative practices in the humanities. This limit is structural and procedural: the work of interpretation cannot be readily performed through the display, and the algorithms and protocols cannot be altered through manipulation of the display. The display algorithms and protocols that generate visualizations are human authored, and thus perform interpretative work, but they are sealed off from direct engagement. Even when displays support a filtered, faceted search for discovery, they are not a means of inputting or transforming data or of modeling the interpretative work. Practitioners skilled in statistically driven work are keenly aware of the ways data production embodies interpretative decisions about the statistical complexity and lifecycles of their data (from parameterization to display). But the conventions they use in these visualizations remain linked to a representational paradigm.</p>
<p>In a representational paradigm, the relation between data and display is unidirectional, the data precedes the display, and the data is presumed to have some reliable representational relation to the phenomena from which it has been abstracted. The display functions as a surrogate for the data—which is itself a surrogate, adequate or inadequate, for some phenomena. Simply put, the display stands for the data, is a re-presentation of the data. But, as has already been stated, visualizations are generally taken to be a presentation, a statement (of fact, or argument, or process), rather than a representation (surrogate) produced by a complex process. Because of their <span aria-label="77" id="pg_77" role="doc-pagebreak"/>presentational appearance, visualizations, as has also been stated above, are what we would term <i>declarative</i> statements. In the declarative mode (in contrast to the interrogative, the conditional, the subjunctive, for instance), statements are not qualified; they seem to simply state <i>what is</i>. As a result, the lifecycle of data production is concealed in these visualizations; the features of their display (proximity, size, scale, color, etc.) are often read as semantically meaningful when they are frequently, actually, the result of display algorithms optimizing screen space, legibility, or other factors that are not intrinsically semantic. As conspicuous aspects of the display, these structures and graphical features are often taken as significant (how close something is to something else, for instance, might be simply an artifact of the display that gets read as meaningful). Reading the artifacts as if they were the underlying or original phenomena, or even accurate representations of or surrogates for it, ignores the complex processes of production and construction. Some features of visual display are semantically meaningful, others are not.</p>
<p>Instead, we should consider that visualizations are usually representations (constructions) passing themselves off as presentations (statements of self-evident fact). Again, in the representational mode, visualizations usually lack certain features. They do not carry author attribution, nor do they contain any account of the lifecycle or parameterization of the underlying data. They are generally produced from a single viewpoint. Finally, they are impervious to direct input or variation in real time. They also erase the circumstances of what we might term their enunciation, or articulation, and thus, they do not contain any markers of the historical and cultural conditions of their production. The ethical issues in assumption of such value-neutral visualizations are similar to those in any other human expression, leaving them open to the same critiques of unacknowledged bias. When they are dynamic, visualizations use conventions based on an overview and zoom model, which supports faceted search, detailed query, and filtered display. These display methods can be very useful when applied to humanities projects and research. In their capacity as discovery tools, these visualizations use graphical display to expose patterns in data, to see data, and ask questions of it. This is particularly valuable for large data sets, and this line of argumentation has been the standard support for the use of visualizations across fields. However, the display and discovery method of visualization does not exhaust the possibilities for the development of other graphically enabled interpretative work. Furthermore, the classic <span aria-label="78" id="pg_78" role="doc-pagebreak"/>formulation of discovery is based on a consumerist model of user experience, rather than one of generative engagement and critical dialogue.</p>
<p>Concept modeling differs from standard visualizations in nearly every approach to presenting information or interpretation in graphical form. Locating concept modeling in a succinct typology of visualizations should help make the specificity of the project clear. Visualization software can be divided into the following categories: (1) drawing programs that generate images algorithmically (e.g., Processing) or through rendering (e.g., Rhino) in pixel/raster or vector formats with surface textures and other visual effects; (2) visual displays of quantitative (numerical or statistical) information (Tableau, Google Fusion, Excel charts, scatter plots, etc.); (3) forced or directed graphs (Cytoscape, Gephi, and other network visualizations) generated through computational analysis of betweenness and other factors; (4) simulations of complex, nonlinear, or dynamic systems (Game of Life, VisSim); (5) visualizations from integrated data analysis (Inscriptifact, imaging, forensics, etc.); (6) visual presentations of data mining or analysis (Voyant, Google Fusion Tables, Tableau). None of these are experience-based, all are driven by strict quantitative and/or probabilistic statistical or algorithmic methods for analysis and display. All use standard metrics, uniformly measured spatial/graphical display, and continuous spatial environments. While these features are adequate for the visualization of information conceived within terms of homogeneous metrics, they are not adequate for the creation of models of varying, discontinuous, or inflected experience of temporal, spatial, textual, emotional, or affective phenomena. While humanistic documents and materials can be reduced to quantitative data through certain processes of abstraction, and for particular purposes (counting and sorting), the dimensions of hermeneutic thought that play a major role in many humanistic works and enquiries cannot be modeled in graphical systems based on features extracted from the natural sciences and its empirical methods.</p>
<p>By contrast to standard visualization approaches, concept modeling does not assume the existence of data or other representations in advance of the act of interpretative work. Modeling is a primary, productive, interpretative act that can be used to create data. Modeling does not re-present data in a chain of surrogates (from parameterization / extraction or abstraction / reduction / standardization / and presentation). Instead, a modeling environment consists of graphical components, activators, and dimensions culled from visual and pictorial traditions to be put at the service of <span aria-label="79" id="pg_79" role="doc-pagebreak"/>high-level concepts (contradiction, ambiguity, comparison, etc.). Modeling assumes that graphical platforms can support interpretation as primary means of knowledge production and/or interpretation.</p>
<p>A simple example should help make this clear: if I have a diagram on my screen and decide that two of the points in the display are related to each other in a particular way, I draw a bold line of connection between them. Connection is an interpretative concept. Connection is not a thing, not an entity being represented, it is a concept that is being modeled. The two points may have been part of a representational display, a conventional chart or graph. They might also have been created on a blank canvas or placed on a map or a timeline. But the point is that the connection between them is expressed as a deliberate and direct interpretative act that is performed graphically by drawing the line of connection. The line is used in the service of the concept and inscribes the interpretative model on the screen. This action models interpretation about the information in the visualization, using graphical means. The existence and weight of the connecting line are then registered in a table or other data structure or format. The data structure can hold a simple quantitative value or an expression of value, calculated as a factor of a variable that changes over time, or is calculated to any level of complexity.<sup><a href="chapter_3.xhtml#chapter3-9" id="chapter3_9" role="doc-noteref">9</a></sup></p>
<p>Concept modeling thus supports direct acts of interpretation in the graphical environment. The visualizations are models of a particular interpretation, and they bear the signs of their production in author attributes, interpretative layers, and other features that stress the “spoken” or articulated (enunciative) aspects of a graphical visualization. They are clearly and markedly rhetorical. The term nonrepresentational, as it is being used here, is borrowed from work in critical cartography and nonrepresentational geography. In that context, the term nonrepresentational is used to suggest that a map does not precede experience or a phenomenological engagement with landscape and its features, but is instead made as an inscription of experience.<sup><a href="chapter_3.xhtml#chapter3-10" id="chapter3_10" role="doc-noteref">10</a></sup> The presumption of representation as an adequate surrogate, as knowledge, is therefore countered by the assertion that knowledge precedes inscription and presentation. The sequence of epistemological events is reversed. A map does not represent a territory, but is an interpretative and discursive artifact.</p>
<p>In concept modeling, the two-way potential of the screen (or other input field, if the interface is created spatially or in physical computing modes or <span aria-label="80" id="pg_80" role="doc-pagebreak"/>other alternative modes) is activated, and the screen serves as a primary site of work. Interpretation is enacted in the screen or platform. The concept modeling environment is designed to include elements, activators, and dimensional features that can be put at the service of interpretative work. These features function at a high level of conceptual work, such as the example of connection given above. By contrast, representational graphic platforms generally consist of a specific set of entities and attributes meant to represent data or things (e.g., timelines consist of points, intervals, dates; maps might have cities, rivers, roads, or borders; and so on). The graphical features of the concept modeling environment are designed to express fundamental principles of interpretation: uncertainty, parallax, contradiction, partial knowledge, and so on. For instance, instead of a timeline that represents events as points, a temporal model is constituted by relations of before and after, simultaneity, duration, slow and fast time spans, and variable models of historical chronology or other conceptual elements.</p>
<p>Concept modeling creates data input through direct manipulation of graphical features on a screen. Imagine a line has been charted from values in a spread sheet. Now imagine that a line of connection has been drawn, a graphical inscription of an interpretative action. The table on the spread sheet can register the addition of a new set of attributes. Extra attributes, termed “affective” to indicate that they are generated through human, individual decisions about significance and importance, can be added. These might require complex calculations of their value if they register in the table as forms that designate forces, probabilities, and other dynamic or emergent properties. No limit exists on the type or value of additional attributes or the relationships that might be modeled in the graphical environment by drawing directly on the chart. The modeling would simply continue to change the underlying data structure through a direct act of interpretation inscribed using graphical means.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Justification</samp></h2>
<p class="noindent">The justification for nonrepresentational approaches to modeling interpretation is that visualizations generated by display protocols have served very well for large data sets processed according to statistical methods, and though these are human-authored and therefore already interpretative and rhetorical, they produce results in the form of statements that conceal or <span aria-label="81" id="pg_81" role="doc-pagebreak"/>largely ignore these aspects of their presentation. The traditional approach to hermeneutic analysis in the humanities is modeled on the idea of a generative reading of a text, event score, performance, or other artifact of the cultural record. Such reading is generally close, individual, and meant to create an argument about how the artifact or text under consideration can be understood. Creating an environment in which to enact this interpretative work, generate data from it, and make it an intuitive mode of input is one justification for this project. But the deeper justifications are related to convictions about knowledge—they are epistemological. As mentioned above, the declarative mode of representational visualizations often causes the artifacts of display to be taken as semantic features of the data, or, worse, of the phenomena for which the visualization and data stand in surrogate relation. In addition, the ability to alter the data structure of a visualization through direct input is largely foreclosed in conventional display.</p>
<p>A modeling environment adds the capacity to engage directly, graphically, in interpretative work on visualizations, artifacts, documents, texts, images, or any other file that is being displayed. In this environment acts of specific, authored, varied, contradictory, collective, and other interpretative readings can be modeled, marked, stored, made visible, revisited, revised, exported, and analyzed. The goal is to support rhetorical, argument-based, interpretative work, not statements that appear to be singular or self-evident. Concept modeling is an alternative to (and augmentation of) the declarative mode of conventional visualizations. One of its crucial epistemological premises is to emphasize a subject-centered, or enunciative, system of graphical expression. Enunciation marks visualizations as situated, partial, historical, authored, observer-dependent, and rhetorical. These shifts, from the declarative to the rhetorical, the display mode to the modeling one, the automatic to the hermeneutic, and the flat, sealed, space of the screen to the multidimensional one of virtual intellectual space and direct input are the core contributions of this project. Concept modeling supports humanistic methods of interpretation as specific ways of working, thinking, and producing knowledge.</p>
<p>To summarize, the intellectual principles of concept modeling are a nonrepresentational approach that creates knowledge and interpretation directly, rather than using surrogates to generate display. The distinction between representation and modeling can be understood as that between the activity of “designing” a house and “modeling” a dwelling. In the first <span aria-label="82" id="pg_82" role="doc-pagebreak"/>instance, you might begin by laying out a plan with a living room, dining room, front door, bedrooms, and so on that assumes a house contains “rooms” which serve specific functions: eating, living, sleeping. The design platform might contain a kit of windows, walls, doors, and other entities from which the “house” is composed. As an alternative, consider a modeling platform that is composed of high-level concepts: shelter, boundaries, ingress and egress, scale, pathways, sightlines, degrees of privacy and proximity, and so on. The “model” created as a result is not entity-driven, but concept-driven, and the graphical platform is the environment in which the modeling takes place. The platform does not represent a house, it models a dwelling. In the first approach, the entities are set in advance in a menu of options as a pick list; in the second, concepts model a space whose functions and specific qualities emerge.</p>
<p>Concept modeling is meant to support interpretative approaches to knowledge which assume that knowledge is partial, situated, constructed, and authored (this differentiates it from empirical and positivist approaches whose assumptions are that knowledge is stable, repeatable, universal, and complete). This distinction can be articulated as the difference between observer-dependent and observer-independent approaches to knowledge production.</p>
<p>The observer-dependent and observer-independent distinction also underpins the difference between hermeneutic and mechanistic approaches to visualization. In hermeneutic visualization, the graphical environment is the primary space for creating, marking, and processing interpretative work; in a mechanistic visualization, a display is generated through direct processing of data, statistical information, text, or other computationally tractable information (information that can be computed). The display in a mechanistic visualization stands in a stable relation of underlying data to representation; the display is a surrogate, even if it can be queried, redrawn, filtered, or faceted, the display rarely changes the underlying data, and when it does, it does so mainly as a change in values, not a change in architecture or structure. In a hermeneutic visualization, no data or other intellectual information has to exist in advance of the process of graphical production (though base images such as maps or texts might be used as the ground on which to register an interpretative, or hermeneutic, production). The interpretative approach is linked to a deliberately marked system of subject-centered enunciation or articulation that shows the position of a speaker and spoken subject.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><span aria-label="83" id="pg_83" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Design of the concept modeling environment</samp></h2>
<p class="noindent">The design guidelines for the graphical production environment are meant to embody the intellectual principles and goals of the project. This work was originally undertaken in the context of the 3DH workshop at the University of Hamburg in 2016. The designs were meant to address the need for a way to work with the elaborate textual markup schemes created in a platform called CATMA. The goal was for these tools to work with Voyant, as well, a platform for basic text analysis. These two display modes were to be complemented by an argument space that would use the same conventions, but as a primary means of interpretative work along the lines described throughout this book. The 3DH environment was supposed to be able to (a) work with existing visualizations and (b) create completely new visualizations that generate data structures. The section that follows was written as a prospective design brief, hence its tense and tone.</p>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Design brief</samp></h3>
<p class="noindent">The conventions used by CATMA and Voyant are both examples of visualizations generated by platforms created specifically for humanities research. The markup in CATMA is a deliberate act of textual interpretation, and Voyant is interpretative by default of the design of the text mining tools. CATMA displays are already direct and nonrepresentational by virtue of the way they are created through direct input. Voyant displays are representations of text analysis, and thus serve as examples of conventional visualization. Both seemed likely to benefit from innovation.</p>
<p>The new visualizations were designed to either make use of a base image or be generated from a blank canvas. A historical map might serve as a base for one of the examples and provide the foundation on which to create spatial interpretations of historical events. But the creation of relative chronologies with nonstandard metrics was an example of modeling directly in the graphical environment, without a base image.</p>
<p>As noted above, the nonrepresentational approach consists of a generalized set of graphical features, interpretative activators or inflectors (activators and inflectors were terms we developed specifically for the project, with activators as tools that did things and inflectors as graphic attributes that showed values). These features were used to assign qualitative or affective value through graphical inflection (e.g., salience, reliability, etc.). It was <span aria-label="84" id="pg_84" role="doc-pagebreak"/>envisioned that any and all of these could be customized for specific projects through labeling or selective use. The dimensions have structuring and syntactic implications for the relations among aspects of an interpretation, but they are not defined semantically the way, for instance, the elements in a map legend might be. The dimensional features are therefore to be understood as components of interpretative work, not as entities that are being represented in graphical form. For example, making a comparison is a fundamental interpretative act, in which values within areas of an image or text are being put into relation to each other. An act of comparison is not entity-driven, but process-driven. The dimensions of the conceptual modeling environment embody principles of such interpretative activity.</p>
<p>The modeling environment was designed to support data inflection, the process of going from graphical input to data/infrastructure modification. As a model is created, modified, and augmented, the data structure is generated through a process of mathematical calculation. Regular tables and standard metrics do not have to be the only data structure created in the process. Branching, layered, crazy-quilt tables and other anomalies could also be generated by the conceptual modeling, which registers the many variable attributes of these structures.</p>
<p>The modeling environment was envisioned to consist of three graphical components:</p>
<ul class="bull">
<li class="BLF">Graphical features (the palette of elements with which to work, drawn from standard literature in the field),</li>
<li class="BL">Activators/inflectors (application of the features to enact, inflect, inscribe, and mark interpretative moves), and</li>
<li class="BL">Dimensions (these draw on conventions of pictorial form such perspective, layering, parallax, etc. put at the service of the many aspects of a hermeneutic analysis).</li>
</ul>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Graphical features</samp></h3>
<p class="noindent">The basic palette of graphical elements for static and dynamic visualization is shared by representational/display and modeling/interpretative approaches. The graphic primitives are taken from Jacques Bertin and Leland Wilkinson and augmented by elements from animation.<sup><a href="chapter_3.xhtml#chapter3-11" id="chapter3_11" role="doc-noteref">11</a></sup> The graphic primitives include: tone, saturation, color, transparency, texture, shape, orientation, size, and position. The dynamic elements include: <span aria-label="85" id="pg_85" role="doc-pagebreak"/>order, sequence, twist, decrease, increase, and flip. Other dynamic graphic attributes include torque, weight, force, and attraction/repulsion. None of these carry semantic value in themselves (though, obviously, certain colors and shapes call forth associations, as do contrasts of size, and so on). But all of these elements could be put at the service of concepts, values, or meaning-producing signs in a standard legend.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Activators and inflectors</samp></h3>
<p class="noindent">Among the activators and inflectors were many that expressed <i>affective</i>, emotionally charged values. Affective (emotionally charged) attributes are not simple statements of quantitative value but are expressions of qualitative value. For example, when creating a map of a particular spatial experience, affective attributes might be used to register smell, comfort, pleasantness, cold, fear, anxiety, etc., such that the geospatial information is generated as “spatial coordinate plus a factor of X.” Such a formulation might also contain a formula for change over time, or modification in relation to any specifiable condition or aspect of the phenomenon. Affective attributes, like other generative and relative metrics, do not have to be arbitrary, but they necessarily include the point of view of their author. The activators introduce syntactic, relational attributes while the inflectors, generally, introduce semantic attributes. Activators and inflectors are not entities, but qualities, and are made of the basic graphical features. Thus, salience might be indicated by glow or luminosity, ambiguity by tonal value and vague boundaries, contradiction by lines of force and so on. Establishing conventions for a set of activators and inflectors relevant to a particular project makes sense, but a fundamental set of argument structures and rhetorical moves, such as those just mentioned, makes sense as well.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Dimensions of interpretation</samp></h3>
<p class="noindent">The concept modeling dimensions listed here are not meant to be definitive or exhaustive. They were the outcome of research for the 3DH project. But they comprise the fundamental moves that can add dimensions to a flat screen space. The system is extensible and customizable, though establishing some conventions of use will lend legibility to the project overall. The dimensions are literal interventions in and manipulations of the screen space put in the service of conceptual modeling. A projection, for instance, should be understood literally and metaphorically. What kind of shadow <span aria-label="86" id="pg_86" role="doc-pagebreak"/>or form is cast by a data visualization when it intersects with another plane (a value plane, ideological plane, hegemonic system, etc.). Some of these moves, like tilt, for instance, may seem obscure at first, on account of their unfamiliarity, but they are meant to suggest ways of turning interpretative work into systematic metrics so that graphical displays are generated affectively as well as objectively. The metrics are dependent on interpretative values, not mechanistic ones. The model makes the values, and the values become the basis of a system.</p>
<p>A list of the spatial moves envisioned in the 3DH platform follows here, and each is described in turn, though a fuller understanding of these requires the graphical images in the appendix. Some of these are variations on familiar approaches, such as <i>annotation</i>. Others are borrowed from conventions of drawing or graphics, such as <i>point of view</i> or <i>tilt</i>. But some are novel to the point of being difficult to grasp in the abstract, such as <i>slicing</i>, though they assume a rich data set that can be exposed along a particular axis or array.</p>
<ol class="num">
<li class="nlf-alt3"><i>Point of view</i> is indicated by a number of features such as author attribute, vanishing point, horizon line, picture plane, now sliders (indicating the position of “now” in a timeline), and multiple viewpoints. Point of view embodies the place from which an image is constructed, and thus assigns the image and its scale to a particular, rather than a general, owner or author. Introducing point of view within data displays dimensionalizes them in ways that radically alter the neutral or objective approach to visualization and returns them to an enunciative system. This shift is crucial for moving from a user-independent model of visualization to a user-dependent one. A point of view can be constructed from a historical or spatial vantage point as well as one owned by an individual or a group. Relative scales (see 8. Relative scales, below) can be used to contrast points of view based on differing metrics. Perspective systems embody point of view by using eye lines, vanishing points, and horizons, all of which inscribe scale and positionality within the scene. Single-point-of-view systems are monocular and omniscient, but the use of multiple perspectival systems is also possible to introduce relative viewpoints (see 10. Parallax below).</li>
<li class="NL1"><i>Layers</i> allow information to be brought forward, pushed backward, and changed in tonal value or intensity. Layers are used to distinguish a <span aria-label="87" id="pg_87" role="doc-pagebreak"/>base layer from the interpretative materials, or, without a base layer, to create a model from scratch. Layers can be used to hold contradictory arguments, varied uses of evidence, or to display any aspect of a project that can be articulated independently.</li>
<li class="NL1"><i>Slicing</i> makes cuts across data objects expressed as visual models, graphical artifacts, or displays to reveal patterns across another axis. Slicing is primarily a discovery tool, but it can be used in an active, modeling, mode to create and study patterns, record them, create analyses in an iterative process of modeling and display. Introducing a slice into a model implies depth that can be actively intervened and engaged within the presentational field.</li>
<li class="NL1"><i>Annotation</i> adds information, labeling, and/or commentary into any model and can be added to any feature of a data set present in a display: a node, edge, point, text, image. Annotations can be recorded in a data structure as attributes noting connections, relations, or other analytic and interpretative features.</li>
<li class="NL1"><i>Tilt</i> moves layers through an angle of interpretative inflection to distort the display. The angle might be generated systematically through a generative metric (rate of change of any variable) or through an interpretative principle (bias, sentiment) or affective metric. The tilt angle can be calculated through a generative process (see 7. Generative metrics, below) from some other feature of the model, or it can be used as a graphical tool of manipulation that reveals some aspect of the model to which a value is then assigned.</li>
<li class="NL1"><i>Projections</i> are common modes of creating mathematical transformations in geometric renderings or spatial constructions. Casting a shadow is a basic projection move and creates a new, distorted, derived version of a form through an angle of transformation. This angle, like other affective or interpretative metrics, can be generated systematically or arbitrarily. If I want to show the influence cast on a scene in a narrative by a specific character, I can project it, for instance, according to an angle of influence, force, power, etc., generated through a contrast of power terms, vocabulary, or any other text-mining tool. Anamorphic projections can also be created using generative metrics (see 7. Generative metrics, below). The plane onto which a projection is made can be a mere convenience, a device to hold the projection. But a plane can <span aria-label="88" id="pg_88" role="doc-pagebreak"/>also have a defined identity, such as a plane of history, of ideology, of bias, and its angle to the projection can be assigned an attribute (e.g., salience, contradiction, ambiguity, etc.).</li>
<li class="NL1"><i>Generative metrics</i> are created by taking a feature of a graphical artifact and using it to generate a new scale. For instance, the lengths of lines between data points on a graph, though they are the result of a change in value, can be used to make a new scale by rotating the line lengths downward to create points on a line that define a new metric standard. The scale generated in this way is not arbitrary, but derivative. Such a metric might inscribe biases recorded as biases, and by mapping a graphical element from one metric system to another the distorting effects become evident.</li>
<li class="NL1"><i>Relative scales</i> are essential for showing differences among taxonomies and other systems of classification, knowledge production, and epistemological models. Relative metrics can be generated from textual interpretation, intuitive graphing, and other ways of engaging with nonstandardized metrics such as varied chronological scales and relative models of historical time. They can be correlated at certain points of alignment, but never fully reconciled since their units, scales, and assumptions about the completeness of their own models are each distinct. The use of relative scales is essential for exposing the differences among taxonomies, worldviews, value systems, and other features of knowledge production, classification, and management. It is fundamental to the humanistic critique of positivist and empirical models of data visualization.</li>
<li class="NL1"><i>Fold</i> allows different areas of a model to be brought into connection with each other in order to see how they relate, what patterns they share and/or make, and what comparisons emerge in the process. Folding is a powerful structuring tool, and making concept models that are multidimensional depends on folds, edges, planes, angles, and other geometric principles. The line of fold can be derived from the action of folding, or it can be determined through a deliberate choice. Folds are able to show change as a contrast of values, rather than as a continuum. Folding can take place at regular intervals or arbitrary ones. Folding also reverses part of the graphic image and allows visual alignments and coincidences to appear.</li>
<li class="NL1"><i>Parallax</i> involves the use of perspectival systems to indicate more than one viewpoint in a model or display. It can be used within representational as well as modeling environments to break the singularity of <span aria-label="89" id="pg_89" role="doc-pagebreak"/>presentation in graphical environments. The degree of parallax, or differential between positions or points of view, can be generated systematically or arbitrarily. Points of view can be unassigned, or not attributed, and used as interpretative tools according to the shifts of eye line, horizon line, and other structural features.</li>
<li class="nll-alt3"><i>Split</i> is a division within a document, scene, argument, or image in order to show contradictions within the evidence or rhetorical direction of an argument. If parallax registers multiple viewpoints, split can be used within a single author’s arguments to refract its multiple aspects.</li>
</ol>
<p>Other spatial moves can be used to model interpretative actions, such as stack, slip, shift, etc. In other words, any graphical action that can add a dimension to the visual field can be given meaning (semanticized). Understanding the links between these moves and their semantic value will require research and study, user testing, and experimental project modeling. Dimensions are used in combination with activators and inflectors.</p>
</section>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">The idea of graphical enunciation</samp></h2>
<p class="noindent">Though innovative in many regards, particularly in some of the dimensions and activators/inflectors, the system should be designed so that it can become intuitive, particularly if users understand that a limited subset of features—layers, annotations, semantic inflectors—can serve as a starting point. The more conceptual features—such as fold or parallax—will probably need time to develop habits of use and legibility. The concept modeling environment is driven by the conviction that interpretative work can be supported by graphical means, and that these means can supplement existing visualization conventions of representation and display. By providing a primary and direct method of doing interpretative work, nonrepresentational modeling augments existing mechanistic visualizations with approaches that are much closer to traditional interpretative methods in the humanities.</p>
<p>The development of a means of systematically inscribing enunciation in visualizations is essential to advancing the interpretative agenda of the humanities. The absence of conventions to mark the “speaker” of a visualization, whether it is a display or a model, hampers the development of an approach that acknowledges the discursive modality of visualization. The inclusion of point of view inscribes data within an articulate (enunciative) <span aria-label="90" id="pg_90" role="doc-pagebreak"/>system so that the display is expressed from a specific historical and authorial position. This allows for contrast, parallax, and multiple views into the same data. User-specific (enunciative) markers allow historical, cultural, or other positions to be registered in the display. Author attribution, the explicit use of positionality as a locator for the speaking (enunciating) subject, and the analysis of the spoken (enunciated) subject, all need to be marked graphically in features that expose the structuring activity of graphical expressions.</p>
<p>Thinking about data visualization as an enunciative system is essential, but it is not a familiar convention of current visualization systems. In addition to mining the conventions of pictorial image production, the project draws on narrative theory, linguistic theory, film theory, critical race and gender studies, and postcolonial analyses where concepts of subject formation (and enunciation) have been developed. Not all of these are text based, and in fact the pictorial conventions provide well-developed foundations for graphical enunciation systems. Developing a set of graphical markers for such a system is part of the research ahead for reasons that should become even more clear in the next chapter.</p>
</section>
<section epub:type="rearnotes" role="doc-endnotes">
<h1 class="BMH1"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Notes</samp></h1>
<ol class="footnotes">
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_1" id="chapter3-1">1</a></span>. Edward Tufte, <i>The Visualization of Quantitative Information</i> (Chesire, CT: Graphics Press, 1983).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_2" id="chapter3-2">2</a></span>. J. J. O’Connor and E. F. Robertson, “A History of Topology,” <a href="http://mathshistory.st-andrews.ac.uk/HistTopics/Topology_in_mathematics.html">http://mathshistory.st-andrews.ac.uk/HistTopics/Topology_in_mathematics.html</a> (November 12, 2004), or Teo Paoletti, “Leonard [sic] Euler’s Solution to the Konigsberg Bridge Problem,” Mathematical Association of America (August 21, 2018), <a href="https://www.maa.org/press/periodicals/convergence/leonard-eulers-solution-to-the-konigsberg-bridge-problem">https://www.maa.org/press/periodicals/convergence/leonard-eulers-solution-to-the-konigsberg-bridge-problem</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_3" id="chapter3-3">3</a></span>. Johann Benedict Listing, biography; <a href="http://www-history.mcs.st-and.ac.uk/Biographies/Listing.html">http://www-history.mcs.st-and.ac.uk/Biographies/Listing.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_4" id="chapter3-4">4</a></span>. Georgi Dalakov, “Sketchpad of Ivan Sutherland,” <i>History of Computers</i>, <a href="http://history-computer.com/ModernComputer/Software/Sketchpad.html">http://history-computer.com/ModernComputer/Software/Sketchpad.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_5" id="chapter3-5">5</a></span>. Dalakov (ibid.) on Ivan Sutherland: “Sketchpad stores explicit information about the topology of a drawing. If the user moves one vertex of a polygon, both adjacent sides will be moved. If the user moves a symbol, all lines attached to that symbol will automatically move to stay attached to it. The topological connections of the drawing are automatically indicated by the user as he sketches. Since Sketchpad is able to accept topological information from a human being in a picture language perfectly natural to the human, it can be used as an input program for computation programs which require topological data, e.g., circuit simulators.”</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_6" id="chapter3-6">6</a></span>. On Neolithic circular enclosures in Central Europe, <a href="https://en.wikipedia.org/wiki/Neolithic_circular_enclosures_in_Central_Europe">https://en.wikipedia.org/wiki/Neolithic_circular_enclosures_in_Central_Europe</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_7" id="chapter3-7">7</a></span>. The balance of this chapter draws on material from Johanna Drucker, “Non-representational Approaches to Modelling Interpretation in a Graphical Environment,” <i>Digital Scholarship in the Humanities</i> 33, no. 2 (June 2018).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_8" id="chapter3-8">8</a></span>. Rhino is an example of rendering software, for instance, and though an argument can be made that the creation of a highly resolved image of an object is a model, even, on some level, an epistemological argument, it just confuses matters to consider drawing platforms and intellectual modeling as doing the same work.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_9" id="chapter3-9">9</a></span>. Mind mapping software is often brought up as an example of this approach, but again, the tools are reductive, the ground on which the figures are drawn is standardized, Cartesian, and inadequate to express discontinuity, affective metrics, and other features of inflected experience.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_10" id="chapter3-10">10</a></span>. Nigel Thrift, <i>Non-representational Theory: Space, Politics, Affect</i> (London: Routledge, 2008).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_3.xhtml#chapter3_11" id="chapter3-11">11</a></span>. Jacques Bertin, <i>Semiology of Graphics</i> (Madison: University of Wisconsin Press, 1983); Leland Wilkinson, <i>The Grammar of Graphics</i> (New York: Springer, 2005).</p></li>
</ol>
</section>
</section>
</div>
</body>
</html>