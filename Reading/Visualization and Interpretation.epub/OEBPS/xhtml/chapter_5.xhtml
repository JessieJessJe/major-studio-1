<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" lang="en" xml:lang="en">
<head>
<title>5 The Projects in Modeling Interpretation, or, Can We Make Arguments Visually?</title>
<meta content="text/html; charset=utf-8" http-equiv="default-style"/>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:ab716dc3-7c3d-4fc9-9c55-4cc6a0edf9ef" name="Adept.expected.resource"/>
</head>
<body epub:type="bodymatter">
<div class="body">
<p class="sp"> </p>
<section aria-labelledby="ch5" epub:type="chapter" role="doc-chapter">
<header>
<h1 class="chapter-title" id="ch5"><span aria-label="111" id="pg_111" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">5    The Projects in Modeling Interpretation, or, Can We Make Arguments Visually?</samp></h1>
</header>
<p class="noindent">As noted throughout this book, scholars working in digital humanities have engaged graphical modes of data display in the service of research across a variety of fields that deal with the cultural record. Historians, literary critics, geographers, and art historians as well as scholars in the social sciences make use of charts, graphs, maps, diagrams, and other graphical expressions in ways that would have been difficult before the advent of personal computers.<sup><a href="chapter_5.xhtml#chapter5-1" id="chapter5_1" role="doc-noteref">1</a></sup> Standard programs and platforms enable production of “information graphics” with little or no programming or technical skill.<sup><a href="chapter_5.xhtml#chapter5-2" id="chapter5_2" role="doc-noteref">2</a></sup> Most, if not all, of the graphical forms built into these programs are borrowed from the natural sciences, or the branches of social sciences for whom empirical models of knowledge production are the norm. In these approaches, graphs use standard metrics, point of view systems are assumed to be ubiquitous or neutral, data lifecycles and sources are not indicated, and other conventions in which display suffices for presentation of information are considered sufficient.</p>
<p>The projects developed here are deliberately designed to explore alternatives to these conventions and their underlying assumptions. They are all based on the conviction that approaches to knowledge that are grounded in user-centered interpretation are fundamentally distinct from those grounded in user-independent approaches to knowledge. Though reductive or crude generalizations that oppose humanist models of knowledge as interpretative and scientific or statistical ones as empirical and positivist are oversimplifications, the simple fact that digital humanists adopted—rather than designed—tools and platforms has led to an unexamined—and in many ways unfortunate—outcome. The graphical forms of visualization are inadequate to the needs of humanists for whom ambiguity, nuance, inflection, and complexity are essential—as is the recognition of the partial, situated, and historically/culturally specific acts of understanding that constitute interpretation. Not only are <span aria-label="112" id="pg_112" role="doc-pagebreak"/>the materials of the humanities unable to be represented adequately by the points, dots, bars, and lines of conventional charts, even at levels of abstraction, but more importantly, the processes of doing humanistic work—making and modeling acts of interpretation—are not accommodated by the graphical means designed for empirical and statistical sciences characterized by discrete components and disambiguated features.</p>
<p>These project prototypes are designed to show the ways visualization could engage with interpretation across the major areas of current conventions. They all share certain principles because of their commitment to finding alternatives to the graphical forms that serve natural and statistical sciences. The challenge is to create legible conventions for modeling interpretation, rather than to simply continue modeling knowledge or things known.</p>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">General principles</samp></h2>
<p class="noindent">These graphical projects are designed to prototype the user experience of six different interpretative activities, each of which is part of humanistic work with the cultural record. The projects are meant to support this interpretative activity, mainly generated either from texts or from textual records which might contain or reference visual or physical evidence, as well as to provide an environment for apprehending the act of interpretation expressed in models. The concept of modeling interpretation depends on the ability to make visible and evident the structure of a model (also understood as an argument) and to be able to compare it with other models. Thus, both the actual work of interpretation and the metalevel work of modeling interpretation are part of these projects’ visions.</p>
<p>The projects touch on areas of intellectual work that are directly engaged by digital humanities tools and platforms. Each of these is distinct in the kinds of data or information on which it depends and in the visual conventions with which it is associated (timelines, maps, networks, charts/graphs, ontologies, and point of view systems).</p>
<p>The projects share a few key features, though each uses them to different degrees and can be customized to generate elements appropriate to the project.</p>
<ul class="bull">
<li class="BLF">The use of affective and/or nonstandard metrics;</li>
<li class="BL">The use of graphical devices to structure arguments and create data input directly (a nonrepresentational approach);</li>
<li class="BL"><span aria-label="113" id="pg_113" role="doc-pagebreak"/>The use of inflection and nuance to demonstrate the non-self-identical, nonrepresentational, character of interpretation;</li>
<li class="BL">The use of point of view systems and lifecycles to expose the constructedness of data;</li>
<li class="BL">The use of interactive, direct input, through graphical means—production, inflection, manipulation, transformation;</li>
<li class="BLL">The ability to be used as display formats for already structured data or markup.</li>
</ul>
<p class="TNI2">All of these projects also share some key principles: First, that visualization is a primary mode of knowledge production that can result in structured data outputs rather than be generated by them. Second, that dimensions of interpretation such as ambiguity, comparison, contradiction, and so on need to be legible in graphic conventions. Third, that metrics need to be generated from interpretations, not used to shape them. Finally, that many of the visual conventions from fine arts and design fields (architecture, for instance) could be integrated into these innovative approaches (as per the features discussed in Nonrepresentational Approaches).</p>
<p>The justification for these shared features and principles is that interpretative work in the humanities, as well as the rhetorical character of humanities documents and texts, requires a system of graphical conventions capable of expressing situated, partial, ambiguous, and subtle approaches to knowledge production that are rooted in historical and cultural positions of the interpreter and the objects under interpretation. This user-centered (subjective) approach to knowledge as understanding is at odds with the user-independent approach that characterizes the empirically and statistically driven approaches of the natural and social sciences. The graphical conventions to realize this interpretative approach have never been adequately prototyped. The visualization and interpretation project is designed to take on the challenge of innovating a set of legible features for doing and presenting interpretative work from a humanistic, hermeneutic, perspective.</p>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">The projects</samp></h2>
<p class="noindent">The six projects for visualization and modeling interpretation are: temporal modeling; spatial modeling; network inflection; modeling interpretation/argument in an evidence-rich research field; multiple ontologies; and enunciative interface.</p>
<section epub:type="division">
<h3 class="head b-head"><span aria-label="114" id="pg_114" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Temporal modeling</samp></h3>
<p class="noindent">Two major challenges arise in using conventional timelines to represent the contents, structure, and relations of items that form the cultural record.<sup><a href="chapter_5.xhtml#chapter5-3" id="chapter5_3" role="doc-noteref">3</a></sup> The first is that timelines designed for empirical data are unidirectional, homogeneous, and continuous. The model of temporality assumed in these timelines is completely unsuited to modeling the complexities of lived, reported, constituted, and produced temporality in human documents, or across assemblages of them. The first challenge is to produce an environment for modeling temporality as relational, not assumed. This requires multidirectional, discontinuous, and nonhomogeneous graphical components. In such a system, temporality, and not time, is modeled. The second challenge is to create a means of presenting multiple and alternative chronologies, or heterochronologies that describe the different chronologies developed to chart historical understanding in different cultural moments and locations. To address these challenges, the temporal modeling project consists of (a) interpretative timelines and (b) heterochronologies.</p>
<section epub:type="division">
<h4 class="head c-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">a. Interpretative timelines    </samp>Temporal modeling was my first project in creating alternatives to standard graphic conventions. It was inspired by a project conceived by John Maeda and J. D. Miller in a collaboration done at MIT around 1999–2000.<sup><a href="chapter_5.xhtml#chapter5-4" id="chapter5_4" role="doc-noteref">4</a></sup> Titled “Grand Canyon,” their project was a framework for arranging digital images on a timeline that stretched back from the surface of the computer screen along converging lines of perspective, toward a vanishing point of the past. The idea was to make more images visible by using the illusion of three dimensions, and thus create displays that vanished into deep time and came forward toward the present. The device was simple, and the project was designed for a mass market. The limitations were the same as those of other standard timelines that assume time as an a priori given that is unidirectional in its flow, homogeneous in its metrics, and continuous. These assumptions are just that, assumptions—within the frames provided by subjective experience, narration, or, in another vein, relativity, time is not a given and is not constituted by uniform metrics or unifying conditions. Humanities scholars cannot use these standard timelines to model the temporal experience of novels, films, aesthetic works, or the materials of news accounts, or temporal relations across documents. A radically different approach was needed.</h4>
<p>The assumptions in standard timelines have a long history, and as J. T. Fraser, one of the major scholars in the field, has noted, every concept of <span aria-label="115" id="pg_115" role="doc-pagebreak"/>time and temporality we make use of, with the exception of that introduced by twentieth-century physics, was known in antiquity.<sup><a href="chapter_5.xhtml#chapter5-5" id="chapter5_5" role="doc-noteref">5</a></sup> The concept of time’s arrow and the apparent irreversibility of temporal sequences is central to the human perception of time in experience, as is continuity of time—we do not have gaps, breaks, or jump-cuts in our sense of time’s passing. Standard metrics are reinforced by the use of mechanical and digital clocks, but here the traditional models begin to meet some resistance. The basic experience of any standard unit—a minute, an hour, a day—varies considerably depending on the emotional state and circumstances of perception. Some minutes are much longer than others from a subjective point of view, though from the perspective of empirical science and its time-keeping apparatuses, that variation has no relevance.</p>
<p>Taking these three principles of standard timelines and trying to use them as a basis for showing temporality in, for instance, a novel is almost impossible. Time sequences jump around within a story. The narrative combines segments of anticipation and flashbacks. The story is told in segments, chunks, with gaps and breaks. The time of the telling, the literal narration, is never the same as the time of the told, the story. Finally, no standard metrics govern narrative time, which changes scale constantly, stretching, shrinking, becoming compressed or extended according to the requirements of the story. Narrative is a part of other documents beyond fiction, novels, plays, or films and is part of the ongoing structuring of news accounts, historical work, and references within and across documents that form the official record of political and administrative activities. The question of what constitutes an event, what duration it has, and when it begins or ends—these are questions crucial to legal, historical, and diplomatic work as well as to forensic investigation and analysis. Graphical conventions to model this kind of textual and experiential temporality did not exist.</p>
<p>The design process started in early 2000 and the first part of the work consisted of deciding what the primitive components of the graphical system should be, how they should behave, and how a user would interact with them.<sup><a href="chapter_5.xhtml#chapter5-6" id="chapter5_6" role="doc-noteref">6</a></sup> This tripartite approach underpins all of the projects here, since from a structural point of view, each has to have a set of components, each of which has certain behaviors, and these have to be manipulated by a user in a way that becomes sufficiently intuitive that it can be used as an authoring environment as well as producing graphics that can be read. The interpretative timeline is meant to serve the work of narratologists or other scholars <span aria-label="116" id="pg_116" role="doc-pagebreak"/>working with situated and experiential temporality in single texts or across a body of texts. This includes any work that depends upon discourse analysis to extract temporal references and frameworks from the rhetoric of statements about when, for how long, and at what rate something will occur.</p>
<p>Interpretative timelines depend more heavily on relational features of texts than on date-stamped information, but they do not exclude one or the other. The basic frameworks of tense analysis, temporal vocabularies, and semantic markup are accommodated by the graphical features (before/after, at the same time as, etc.). But the interpretative timelines also include models of semantic inflection that allow the codependence or linked influence of events, points, or periods to be demonstrated. The interpretative timeline is meant to be able to work at a very small scale of granularity for narrative analysis, but also work with large corpora (collections) of documents to create analysis and display of temporal concepts across interrelated documents (such as ongoing newsfeeds and their analysis).</p>
<p>The first step was the creation of the basic scheme of components. These consisted of events, intervals, and points, each of which could carry <i>semantic</i> and/or <i>syntactic</i> inflections.<sup><a href="chapter_5.xhtml#chapter5-7" id="chapter5_7" role="doc-noteref">7</a></sup> The semantic inflections were basically attributes that could be added as graphical features, like glow, tonal value, color, or texture, to add information to an element. The syntactic inflections linked components through properties like anticipation, regret, causality, influence, or connection of any kind. In addition to these basic elements, the design included a “now slider,” which was meant to indicate a viewing point in the present. The temporal modeling scheme had only one now-slider, and it could be progressed to show changes in the temporal model. An event might diminish in importance, an interval might stretch, a point might cast a shadow of anticipation ahead of it and so on. In every instance, the concept of temporality, not time, was in place through the insistence that the model always conceive of temporality as time <span class="symb">+</span> a factor of some kind (emotional, subjective, rhetorical, and so on). The behaviors of the components included “snap-to” lines, ability to stretch, layer, fade, and so on. The user was given the ability to add tick marks to lines, rescale, add labels, manipulate objects and elements, and so on. Multiple now-sliders linked to points of view within the platform could support multiple narratives simultaneously.<sup><a href="chapter_5.xhtml#chapter5-8" id="chapter5_8" role="doc-noteref">8</a></sup></p>
<p>Once the components were determined and designed, an interface was added to manage various models, layers, and other features of the project. <span aria-label="117" id="pg_117" role="doc-pagebreak"/>The infrastructure was built to link the graphical components to an extensible markup language (XML) scheme, but contrary to the usual digital humanities methods of creating markup in XML and then generating a display, this project began with the graphical platform as the primary authoring space. The models were generated from a reading, or a historical event, by constructing the image with the components, their labels, changes over time, influence on each other, and so on. These graphical models were stored as XML and could be exported in that file format.</p>
<p>The built-in limitations of the project came from its reliance on a Cartesian grid. We did not have the technical capacity to generate nonstandard metrics. The regularity of that structure made it impossible to introduce the kind of warping transformations that could indicate affective forces at work. The use of stretchy timelines and also blown-up segments produced through a recursive attention to detail were not possible in the system as designed. Nor did the project develop sufficiently to work in dialogue with XML to generate a display from markup in an iterative process of back-and-forth between graphic modeling and textual markup and XML. This would have supplied a feedback loop between the interpretative work, input, structured data values, storage, display, and so on in an iterative mode.</p>
<p>This project was developed to proof-of-concept stage with workable features, layers, export and storage functions, and an administrative infrastructure for managing models.</p>
</section>
<section epub:type="division">
<h4 class="head c-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">b. Heterochronologies    </samp>The idea of heterochronologies, or multiple timelines created from different cultural or historical understandings of time, arises from some of the same impulses as temporal modeling. In particular, it recognizes the need for nonstandard metrics that embody alternative models of the organizing framework of historical events. The project points toward the idea of being able to contrast and compare ontologies exposed in a graphical format, which will be described below. The understanding of the history of human culture has produced a striking array of different chronological schemes. Some of these overlap, coordinate, intersect, or can be correlated, but others cannot. Respect for the cultural otherness of the past, as well as for the distinctions among different models of historical time, requires a graphical system that does not force alternative chronologies into a single frame of reconciliation. A precedent for this is found in manuscript work by the third- to fourth-century scholar Eusebius, one of the most significant chroniclers of antiquity, where multiple chronologies <span aria-label="118" id="pg_118" role="doc-pagebreak"/>are exhibited in columns across pages that are not organized by a single underlying or unifying grid. Creating an environment for doing this work within a digital environment is crucial as a representation strategy and also an interpretative one.</h4>
<p>Each chronological scheme should be able to be produced according to its own component parts, scale, order, and structure and then layered into a relationship with others (depending on the appropriateness of correspondence or lack thereof across the schemes). So a set of metric (measurement) variables, with the organizing features of each chronology (events, duration, points, milestones, breaks, absences, questions, and so on) will be created as an effect of interpretative engagement. Variable chronologies do not have set start or end points and do not have standard annual or chronological markers or structures, but reflect the models on which they are based or created. Chronologies will have whatever extent and granularity the historically or culturally specific project requires. Fictive chronologies can be accommodated in the scheme.</p>
<p>My need for a way to present alternative models of historical chronology arose directly from work on a text by Edmund Fry, the 1799 <i>Pantographia</i>, a compendium of samples of all scripts known to the author (also a printer–type founder) at the time. Fry’s extensive research resulted in the elaborate production of specimens, but also recorded their sources along with cited excerpts about their historical origins. Thus, a script might be described as having its source “in ancient paintings,” or as having been created “after men had lived long enough in a state of society to perceive the insufficiency of inarticulate cries and gestures.” The chronologies on which Fry was drawing at the very end of the eighteenth century were biblical, historical (linked to particular events and secular dates), or keyed to the dating system that depended on the four-year cycle of the Olympiads. These were sometimes stated in relative terms (before, after, during another event), sometimes descriptive (e.g., “revealed from Heaven”), and sometimes linked to specific events (“at the invasion of the Spaniards”). These modalities of relative, descriptive, and specific events were linked to the cosmological, biblical, historical, relative, and other timescales. Fry’s historical references cannot be unified into a single system. To do so would do a violence to the cultural otherness of the past and disregard the extent to which Fry’s understanding produced a complete explanation of the historical past. The dates in his documents could be coded using a scheme <span aria-label="119" id="pg_119" role="doc-pagebreak"/>that identified them as belonging to one of the several timescales: C <span class="symb">=</span> Cosmological (big time scale, no specifics); B <span class="symb">=</span> Biblical time scale (5000<span class="symb">+</span> years, reference to events); H <span class="symb">=</span> Historical time scale (actual dates); R <span class="symb">=</span> Relative time scale (frame unclear); O <span class="symb">=</span> Other time scale. For example, dates like “1713,” or “93” are historical; “authors pretend that Moses and the prophets used this letter” is biblical; “brought from Heaven by the Angel Raphael, by whom it was communicated to Adam,” is cosmological; “when the Christian princes made war against the infidels” is relative, and so on. A markup scheme can certainly be generated for these values, but they cannot be placed in a grid governed by one metric.</p>
<p>No single timescale works for all of these dates, and none of them conform to the historical timescales that emerged after James Hutton, Charles Lyell, and Charles Darwin transformed understanding of the ages of the earth through their discoveries.<sup><a href="chapter_5.xhtml#chapter5-9" id="chapter5_9" role="doc-noteref">9</a></sup> The worst possible solution to portraying the highly nuanced and complex information in this historical document would be to map all of its specifics onto a single unified timeline constructed in terms of current models. The bias of presentism erases historical otherness. The result would be to flatten the information in Fry’s carefully transcribed citations, and to thereby ignore the very rich understanding that can be derived from them. Fry had no problem making use of multiple chronologies, and he saw them all as valid within their own frameworks. Our understanding of that position depends upon being able to respect and present these heterochronologies in their specificity and being able to fully appreciate their sometimes contradictory and sometimes simply different models of historical time. Again, the graphical scheme requires use of multiple metrics within the same graphical space, and some means of showing points of connection across them. The system is meant to be used for creating and displaying chronological schemes from historical and cultural sources so that they can be compared without being reconciled into a single overarching system.</p>
<p>This project remains in the conceptual phase of development with only hand-drawn or screen-sketched versions of the prototypes. Because chronologies are a form of classification and description, this project is similar in the challenges faced by that of comparative ontologies (see below).</p>
</section>
</section>
<section epub:type="division">
<h3 class="head b-head"><span aria-label="120" id="pg_120" role="doc-pagebreak"/><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Spatial modeling</samp></h3>
<p class="noindent">Spatial and temporal modeling share a conviction that neither “time” nor “space” are a priori givens within human experience and perception, but are always constructed. That construction can be shown, given form, and demonstrated through visualization techniques. The rationale for this project is to create a systematic approach to portraying spatial information from an affective, or subjective, perspective. The founding principle is that space is never given, only experienced, particularly within the representations of narratives, historical events, performance, planning, and experience. The space of an open square is different at all times of day, on different days of the week, and in different seasons. It is also experienced differently by individuals with different profiles and even by the same individual in different roles. The ability to model these experiential features of space requires that we create an input feature that lets the space be inflected, warped, or otherwise inscribed with values. The space should come into being in part through these means, even if it is indicated in advance in a standard mode such as a map, schematic outline, or other format. Imagine a room emerging through the details and information provided by a narrative, rather than created wholesale. Just as temporality is time modified by a factor, so spatiality is modeled with various factors.</p>
<p>We don’t perceive space—or landscapes—from outside them, nor, rarely until relative modern times, see them objectified, as from the air. Though cartographic models are much older than air flight, early maps were often records of encounter, particularly with unknown lands. All maps are projections, and in the well-known truism of cartography, they are all attempts to show a three-dimensional form on a two-dimensional surface. This is true no matter what the scale of the map, though maps that take in larger territories are more conspicuously marked by the distortion of chosen viewpoints than those at smaller scale. The creation of projection systems to compensate for distortion always involves a trade-off, and the compromise to sacrifice accuracy of size for precision of position or relation depends on the use to which the map is being put. Orientation, north-south biases, and other matters are also well-known features of cartographic conventions.</p>
<p>But the concern here is not so much with the standard problems of projection, but rather with the ways in which humanistic documents register spatial information, are used to create spatial models, and are embedded within models of space that, traditionally, do not involve any affective or experiential features. How would a digital humanist expose the spatial <span aria-label="121" id="pg_121" role="doc-pagebreak"/>imaginary of a work? Is James Joyce’s <i>Ulysses</i> to be mapped onto a plan of Dublin with pins and points as if the city were a container for the experience? The complex codependencies of the narrative and its relation to spaces, references, and places require a different mode of modeling.</p>
<p>The structure of this project needs to include use of preexisting materials, like maps or plans, photographs or other depictions, of a built space as references, but it should also allow for a spatial model to be built directly from references and evidence, creating variable metrics. In the first instance, imagine a map of a battle or struggle and the ways the terrain is perceived by different figures within the event depending on their familiarity with the space, eye lines within the space, pressures of the events and moments or degrees of danger to the individuals. In the second instance, imagine a creation of a geographical terrain according to the narrative of its discovery. This does not need to be an instance of colonial contact to require a constructive approach; it could be a story of travel or discovery in other circumstances, or the production of a geography from partial evidence. What are the spaces depicted in novels? Films? Historical references? These provide only points of information, not complete descriptions. In fact, no full description of a space is ever available and the mediating process of knowledge of a space is like that of a text or aesthetic work.</p>
<p>The components of interpretative modeling of spatiality need to include ways to indicate the process of constructing a space through acquaintance with it, experience of its qualities, the ways evidence contributes to its emergence as a model. A system in which a map is layered so that only parts of it come into view, or high focus, and only when there is evidence to support the interpretation, would be completely different from the current approach to mapping in which a historical or contemporary map is used as a base image, then marked with pins or points that might also be linked to bits of evidence, but without having any effect on the geographical representation. If a space is created only through evidence, then it calls that process of spatial visualization to attention. Similarly, if a geography is morphed through affective experience, then this should change the coordinates and topography of the map. The idea of heterogeographies depends on an input system that allows a user to stretch, pull, increase, or decrease any component of the metric on which the space is drawn.</p>
<p>The components of a spatial modeling system would include a point of view system that could be occupied by one or more participants. This <span aria-label="122" id="pg_122" role="doc-pagebreak"/>would allow the spatial model to be viewed from within a subject position as well as from outside it. The features for generating an affective metric (or variable metrics) to morph the standard grid would need to carry information about sightline and view window, area of impact and influence, rate of change and degree of stability of any phenomenon in respect to the space, and a legend for identifying types of events or elements, their degree of ambiance, resistant forces, limits, etc. In other words, any and all features of spatial experience would need to be able to be modeled within the environment. The simplest spatial models might be those created from textual evidence, and gaps in the historical record or narrative would be made clear as would the relative weight, authority, and value of the evidence.</p>
<p>Experiential and evidentiary models are a crucial feature of spatial modeling. So is the ability to create a workflow that would take features of text analysis and topic modeling back into an expressive dialogue with coordinates in a standard system and inflect these so that the landscape morphs. In such a system, frequency of reference would register in some way on the map—simplistically, this could be by a change in size, tone, or position. All cartographic features should be able to be manipulated as a “factor” of their experience and the results should be able to be displayed as a warped, ripped, cut, or partial map.</p>
<p>The two modes, experiential and evidentiary, are not mutually exclusive. In each case, the approach to implementation involves some of the same features. Either the spatial references can be used to build up an image or the evidence can be used against a base map or image. The coordinates on any map project would be malleable, able to be pulled and stretched. Point of view systems need to be enabled so that the space or geography can be seen from a particular perspective, and multiple viewpoints should be able to be embedded in any model. A legend that uses semantic and syntactic inflections, similar to those in the temporal modeling environment, allow for the addition of attributes, as well as labels, or interconnected causal connections and relations (something that expands, spreads, smells, contaminates, or has any kind of effect from one region to another would be connected syntactically). All models need to be able to be advanced through time along a slider or other device. Completeness of any model should be an effect, not an a priori given, and the degrees of focus, granularity of detail, and expansion according to either amount of attention or evidence should be fine-grained enough to allow a tight correlation between information or evidence and the rendering of the image. Spatial models include <span aria-label="123" id="pg_123" role="doc-pagebreak"/>three-dimensional virtual constructions of space (for archaeological, architectural, cultural, narrative, or other sources to be modeled) and maps (of territory, experience, events, and so forth). In all cases, the affective dimensions of modeling are crucial to the shape of the outcome. Spatial experiences are specific to circumstances, and models should be able to express these specific characteristics. A space and an event can be tightly related in terms of their model, and the relation between occurrences and spatial conditions and features should find expression in spatial modeling.</p>
<p>The basic implementation system consists of a staging space (two- or three-dimensional, with metrics able to be specified in standard and affective formats) and/or a reference image (or images—photograph, drawing, record of any kind, and/or map). This basic space and/or image should be able to be manipulated by and through its coordinates and/or projection system. As mentioned above, point of view and perspectival views should be available to insert the model into an individual and/or shared or multiple viewpoints. Sight lines and view cones should be able to be specified. Geographical and dimensional features should be able to be sketched and modeled. Evidence should be embedded and viewable, and elements/features of the cultural record should be linked to their graphical expression. Textual evidence should be able to be data-mined for coordinates (vague or specific). The use of semantic and syntactic attributes should be customizable, though a basic set of inflections should be built into the system. The use of affective metrics—metrics generated from subjective experience, not used simply to register it—is essential to both spatial and temporal modeling. Variable metrics allow for contrast and comparison while also addressing the problems of rational graphical systems of spatial representation.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Network inflection</samp></h3>
<p class="noindent">All features of spatial and temporal models have potential to be embedded in relations. But in a network, the chief structural feature is the <i>relationships</i> among components. The data structure for a network has a tripartite structure so that the relationship can be specified. The standard network visualization consists of a node and edge—a point and a line connecting it. Each can carry weight and also other attributes. These can be indicated by color, size, or other graphical features. However, most network diagrams reduce all relationships to the same presentation and make static representations out of dynamic conditions. They are premised on a characterization <span aria-label="124" id="pg_124" role="doc-pagebreak"/>of entities as discrete entities, or nodes, that are not affected by the conditions of relations in which they are involved. This is a highly mechanistic characterization of nodes (and edges), whether they consist of human beings, institutions, or events. The model does not allow for any influence or effect to transform either the node or the edge relationship as a result of the dynamics between them, change over time, or any other of the many factors that would feature in an actual relationship. Inflected network visualizations would be dynamic, they would include change across time, and they would be based on a notion of the “nodedge” as a combined node-and-edge effect of codependencies that are the very substance of relationships. The rationale for this project is simple, that the current node and edge model is inadequate to show the many dimensions of relationships, their specificity, distinction from each other, and change over time.</p>
<p>The structure of the project allows graphical input to create attributes and values for the basic data structure. The node and edge can be linked or manipulated independently. Either can be increased or decreased, given attributes (inflammation, steady state, diminishment, intensity, etc.). When the node and edge are linked into a <i>nodedge</i> system, changes to one or the other, or to linked nodes, would reverberate throughout the system. Systems can be bounded or open, inclusive or selective, and these features can also be managed with a timeline on which such features change across an interval or at a particular critical moment. The conceptual framework is simple—that networks are living, dynamic, and constantly changing, not static structures comprised of parts that are identical to each other. Input into the models should be direct, graphic manipulation linked to a paint box of attributes, each of which is indexed to a data structure and value scale. Data-mining from texts and direct input from tables with static, multiple, or dynamic attributes will also provide input. If-then statements should be included in the table so that relationships can be modeled according to variable factors and transformations. These conditions could be linked to terms in a linguistic sentiment analysis and also to locations in a text or corpus (e.g., extracting information about reports on the Trump-Putin relationship from news feeds and sources over time).</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Modeling interpretation in a rich research (discourse) field</samp></h3>
<p class="noindent">This project integrates the argument space and evidence in large and small corpora. The goal is to create a navigable and legible graphical expression <span aria-label="125" id="pg_125" role="doc-pagebreak"/>of the argument space or spaces (multiple pathways, arguments, narratives, and discursive interpretations can be generated from any discourse field). This project also makes use of the tools of topic modeling, data mining, and other analytics as part of the evidence that can be generated and linked to the models. The project seeks to create a visual convention that is legible and allows user interaction and engagement, as well to support active two-way display and modification.</p>
<p>Take a complex combination of documents for a research project and imagine all of the ways it can be used, connected, analyzed, and interpreted. Because multiple, even infinite, potential interpretations can be imagined and produced, the system has to be capable of holding many arguments made from the same evidence. One way to describe this phenomenon is that a discourse field is comprised of evidence and a reference field is constituted by the reading that the discourse field supports. An archive of papers from an institution can be read as a political history, as personal sphere of influence, as a record of critical events and issues, and so on through a varied set of individual readings. Each reading is structured by an interpretative model. An analogy would be to imagine the infinite number of constellationary figures that can be drawn among a field of stars. The stars are the evidence, the documents, the objects in the discourse field. The connections among them are the readings that create a reference field—the image/figure is an argument about how the configuration of the stars can be read.</p>
<p>The basic rationale for this project is to find a way to support and expose multiple readings and interpretations in a discourse field and show and compare the relations made by different arguments among the pieces of evidence. The field itself might be constituted differently for the different readings, and links to collections, materials, documents, and evidence would be differently constructed in each instance. Again, imagine, for example, a repository that documents an ancient site, its bibliographical history, its excavation, and the dispersal of artifacts, drawings, records, reexcavation models, and other materials relevant to the site. Links outward from that repository would vary according to projects, linking it to other sites, excavations, professional practices, theories of archaeology, individual figures, historiographic materials, and so on in an unlimited proliferation of possibilities. Or, it might be part of a study of animal habitat and changing climate conditions. The nonunitary nature of the reference field arises from the fact that no two readings or interpretations are alike. The discourse field, even if it remains bounded and <span aria-label="126" id="pg_126" role="doc-pagebreak"/>unchanged, would still support a wide range of interpretative projects, like pathways through a complex physical site do. When the evidence is all in view and available, the job of the scholar is to provide a reading, a path, an interpretative introduction to the discursive materials.</p>
<p>The project takes a nonrepresentational (i.e., generative, argument-driven) approach to the graphical display of models of interpretation in relation to a complex discourse field. The analogy of layers of pathways or tours of the materials is appropriate here, though of course the pathways need not be linear, and the display would not be limited to two dimensions.</p>
<p>The project could make use of data analytics as part of the input stream. Topic modeling, text mining, network analysis and other methods of analyzing and presenting interpretative work could be integrated into the display. These would be activated by filters and selective display with point of view and now-sliders to identify author-subject positions. Analytics might pull certain evidence to the fore or expose connections among elements in the discourse field. In this regard, the project would draw on other features built into the discovery tools in nonrepresentational approaches. Allowing direct interaction and manipulation of the relationships and argument structures in the discourse field is a crucial aspect of the project—perhaps the most crucial, as it would allow for an intuitive interface to the problem of modeling interpretation in a rich discourse field. Determining what the interpretative moves are, what the fundamental argument structure should be, and how the use of inflections and attributes can be employed would build on already described feature sets of other projects. The chief difference between those projects and this would be the extent of the discourse field, the open-ended nature of the connections between a bounded field and an extensible one, and the complexity of the model. In order to draw substantive content into the argument space, the graphic display would need to support an authoring function that would be as minimal as annotation and as maximal as full writing practice, with both linear and nonlinear structures.</p>
<p>The project would use the graphical interface as a structuring environment supported by a display/discovery space; the graphical interface allows a user to create an argument that becomes part of the structured data, rather than simply working to display the already structured data in a table, database, or file. It is nonunitary because it supports multiple (infinite, open-ended, nonsingular) interpretations by one or more users. And the argument can be stored as a data structure, independently.</p>
<p><span aria-label="127" id="pg_127" role="doc-pagebreak"/>The term reference field (or plane of reference) here is meant to describe the constructed space of interpretation; it is tractable as a text or organization of evidence within an explicit structure; in this sense, iteratively, the reference field becomes evidence itself for the next cycle of analysis but in the first instance, it is created on the basis of the discourse field, which is the collection of evidence—documents, photographs, maps, files, tables, data, any artifact that is being used for research. The work of modeling is the primary, active creation of an argument structure or organization—as opposed to display, which is a secondary expression of an already structured data set.</p>
<p>The problem being addressed by the project is to see if the active creation of argument can be given graphical expression in a way that is legible and intuitive to produce and to navigate. The argument is a stand-alone discourse but it is also dependent on and related to the underlying field of discourse (the evidence on which the argument is based). What kind of visualization would be useful so that the interpretation can be “read” for its argument but also point to the evidence on which it draws? To what extent are latent arguments within evidence able to be exposed through this process as well?</p>
<p>The project has various functional requirements which combine the feature sets of the rest of the projects. These include: the ability to create and express an argument in relation to evidence; links to and anchors in specific pieces of evidence (digital artifacts); the ability to use open linked data and metadata to perform analyses; the ability to use analytics—data mining, text mining—as evidence; the capacity to show the argument as a model in graphical space; the ability to interact with the models and track back to the evidence; the ability to modify the model and work with it responsively; the capacity to maintain and preserve alternate (infinite) readings of the evidence; versioning ability and ability to track back into argument development to show the lifecycle or at least partial history of the development of the argument.</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Comparative ontologies</samp></h3>
<p class="noindent">Classification schemes for knowledge organization, known as ontologies, are based on structures that are themselves semantically meaningful and legible. Consider the basic inventory of life forms and their organization by domain, kingdom, phylum, class, order, family, genus, and species.<sup><a href="chapter_5.xhtml#chapter5-10" id="chapter5_10" role="doc-noteref">10</a></sup> This is a hierarchy organized from general to specific, with each lower level inheriting the properties of the level above. Does it conform to the actual description of <span aria-label="128" id="pg_128" role="doc-pagebreak"/>living beings and their connections to each other? Yes and no, and the ways in which life forms are classified has transformed considerably under influence of the study of genetic material and markers of species identification, but also, with recognition that the strictly hierarchical system of identification does not account for the way species differentiate. Completely different descriptions of living beings, or parts of the larger domain of living things, organize them according to other criteria—edible or not, taboo, to be feared or not, able to be domesticated, useful for their skin or fur, able to be bred. Cladistics provide a way to assess the percentage of shared characteristics species have and when they might have branched from a common ancestor. The branching structures in these systems do not match the hierarchical trees of the kingdom to species models. The ontologies that describe these categories of description are necessarily different from those that organize them simply as living things with particular morphological characteristics.</p>
<p>In addressing the cultural record within a long historical timeframe and a broad cultural one, a challenge arises with respect to preserving varied ontologies and using their specific features and qualities as legible components of a structured worldview. As organizations of knowledge, they embody and express cultural and historical understandings. The point of preservation is not to force these varied knowledge systems into standardization, but to find a means of exposing their differences and making them legible in a meaningful way. This project addresses the issue of comparative ontologies as a politically charged, culturally necessary problem in the management of the cultural record.</p>
<p>The rationale is simple: in order to avoid hegemonic standardization that represses cultural differences, we need systems that preserve differences and expose the specific features of the organizational structure. The challenge is to conceive of the terms of comparison and to consider how points of contrast and connection can be structured and made legible. Each ontology has to be considered as a whole, and its structuring principles made clear in graphic, schematic terms: hierarchy, table, intersecting areas, multiple discrete parts held in aggregate, etc. In other words, what <i>is</i> the whole and how are the part-to-whole components organized? Faceted classification systems, which operate using a nonhierarchical set of features, each with its own vocabulary and criteria, have yet other structural properties.</p>
<p>The variety of ontological ordering systems is much greater than in chronological or temporal ones, though temporal schemes are themselves <span aria-label="129" id="pg_129" role="doc-pagebreak"/>ontologies—classification schemes for organizing knowledge about a topic or subject area. Consider the problem of creating a comparison between the ways an indigenous community views its artifacts and the ways archaeological researchers or art museums organize these same artifacts. The differences are important, and each organizational scheme tells us something about the circumstances of use and cultural conditions of its development.</p>
<p>Another pressing issue arises from the development of linked open data systems and the need for exchange and correlation among varied legacy systems of knowledge organization. The challenge is not merely that of being able to find and access individual units of information within and across schemes, repositories, and formats. Because the cultural and semantic significance of any item, object, document, or term is dependent upon its place within the larger relational scheme, making a single crosswalk on an item-to-item basis does not adequately resolve the problem of comparison. Consider, instead, an emergent master list comprised of every object/entry or term in every classification system that is part of the comparative scheme. Each access to the term produces a graphic display of the ontologies of which it is a part. The formal structure of these systems could be exposed as a semantic system in which position, meaning, and value are integrated. These could also be filtered for search and display to promote legibility, and various scales of graphical comparison would allow for more and less detailed examination.</p>
<p>Active engagement for organizing documents, objects, or terms into an ontology would be facilitated by an interface that allows an ontology to be created directly through drag, link, place, position actions on the part of a user. This would be particularly useful for archival work and for creating multiple ontologies in a single collection where such issues as provenance, collector’s imprint, original order, alternative ordering systems (authors, titles, dates, place of production, chain of reaction/response) might also be usefully developed. Subsections and partial organization schemes within a larger collection could also be facilitated in ways that relate to the argument structure and discourse field described in the previous project. Preserving ontologies from on-the-fly organization would create structured data for preservation, modification, and reuse. The graphic conventions for display would be inconsistent across ontologies, but could generate comparisons based on points of overlap, contrast of scales, and structuring principles, through locating common or shared components and exposing their <span aria-label="130" id="pg_130" role="doc-pagebreak"/>relative position within a scheme. Learning to read schemes of organization for their graphical arguments would be a side benefit of this project (hierarchical and not, extensible or fixed, faceted or linear, etc.).</p>
</section>
<section epub:type="division">
<h3 class="head b-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Enunciative interfaces</samp></h3>
<p class="noindent">Ideology is always at work in the linguistic components of a site. But the ideology of interface, as described earlier in this book, works in part through the obfuscation of the relation of speaking and spoken subject of enunciation enacted in the mechanisms of display. The apparently neutral graphical structure of a flat screen, a rationally organized display, and conventionally organized space of menus, navigation, and information organization all carry signs of enunciation. All are part of systems that position a spoken subject of graphical enunciation within a power relation to the speaker. How to show these relations? How to intervene in the conventions of graphical user interface to expose its workings? What kind of “reveal codes” feature would show the assumed speaking and spoken dynamics of a site—and also show its connections to other sites, institutions, or authoring and authorizing groups of which it is a part?</p>
<p>This chain of production, very hard to recover, poses a challenge for data analysis as well. Data lifecycles are rarely exposed, and the creation of visualizations usually begins with a data set, rather than with any engagement with how that data came into being. Data are also “spoken”—they are part of systems of enunciation whose workings are concealed.</p>
<p>The interface challenge is different from that of the data set, but both involve creating some mechanism and convention for identifying source, speaker, and life cycle of production. In the case of the interface, a solution might introduce a graphical code that translates apparently neutral organization into zones, and modes of address into a legible system. Just as the markers of “I” and “you” are clearly identifiable in a linguistic utterance, so the terms of address need to be made legible in a graphical expression. The chain of production indicating “who” the speaker is in any instance—where the source of the site resides, who hosts—could be made explicit as well.</p>
<p>For data production, the task is to expose some of the procedures and steps by which data is created, selected, cleaned, and processed. Retracing the statistical processes, showing the data model and what has been eliminated, averaged, reduced, and changed in the course of the lifecycle would put the values of the data into a relative, rather than declarative, mode. <span aria-label="131" id="pg_131" role="doc-pagebreak"/>This is one of the points of connection with the interface system and task of exposing the enunciative workings. But data lifecycles and models could be embedded into any graphical display, showing how the original data set and sample were related and what the stages were that led to the data set from which any graphic is generated. This kind of analysis is central to the understanding of electoral processes, consumer patterns, opinion polls, and also the kinds of projects that generate topic models, network analyses, and other outputs from the cultural record. <i>What percentage of what record, massaged according to what parameters, has led to the data set?</i> The graphic would have some of the properties of bringing a focused image out of a blurred background, but also aggregating and simplifying into a coarser pixel resolution as things drop out of the data set. Students’ horror when they are exposed to the task of data “clean-up” is a clear indication that being able to show data lifecycles is a crucial part of analysis and display.</p>
<p>Data input is structured in tables, style sheets, xml, and html. None of these are conspicuously marked with regard to the way they function as enunciative structures. A graphical input to assign a speaking role from within the interface would add an attribute to the data structure. The display could be filtered according to attributes. Data lifecycles would be shown through a sequence of graphical displays that provide information about the steps through which the data was refined, and the changing models according to which it was structured. Author attribution for data sources, and connections to networked resources that provided the data, counteract the apparent neutrality of data presentation. Standard conventions do not show the lifecycle of data production or the variations and complexities within extant data sets, they reduce numeric anomalies and specificities to generalizations and aggregates. An innovative approach would reveal the multiple dimensions of data, its irregularities, complexities, variations, and the conditions of its production while also inserting point-of-view systems within the data to show that it is an act of enunciation, created from a position within data production, not outside of it.</p>
<p>The projects are structured around a set of identifying features to mark enunciation and distinguish speaking/enunciating and spoken/enunciated positions. Each involves a degree of tracking back into lifecycles of production and authorship. The data lifecycle has a more specific and focused attention on the statistical transformation of data and the models according to which it was created, manipulated, transformed, and presented. The <span aria-label="132" id="pg_132" role="doc-pagebreak"/>conceptual features of the projects are aligned in their commitment to exposing the unstated authorship concealed in the structure of the graphical display. The apparently neutral declarative statements of interface and data display share an ideological agenda <i>to simply appear to be what is.</i> Taking apart the pseudo-transparency by showing the workings and apparatus of the interface and graphical display of data is a crucial act of hermeneutics applied to information displays and systems.</p>
<p>To make these points vivid, we can briefly examine the specifics of cases. Consider the contrast between two digital platforms, both instances of what we term <i>knowledge design</i>. The first is an interface designed by Anne Burdick for a project of the Austrian Academy of Sciences. A team of linguists and social scientists worked for twenty-plus years to transcribe, make facsimiles of, and markup (with tagsets), the thirty-seven-year (1899–1936) run of the journal <i>Die Fackel</i> (The Torch).<sup><a href="chapter_5.xhtml#chapter5-11" id="chapter5_11" role="doc-noteref">11</a></sup> Edited by the writer Karl Kraus, the journal charts the peculiarities of language he used to encode criticism in an era of rising fascism. Burdick’s interface is a skillful site of mediation between the multiple dimensions of the repository and the functionalities it supports. Her design creates an environment for research that interconnects the facets and features of the various files, formats, and their affordances. The user/viewer of this site is guided into use of the materials—whose content is as substantive and mordant a critique of the role of language in ideology as any ever produced. The viewer’s sense of agency is rooted in the legibility and apparent transparency of the interface. In fact, much processing and infrastructure are rendered invisible by Burdick’s design, as it is neither necessary nor useful for a researcher to see the file structures or pipeline that push content to the screen. The skills Burdick brought to this project were conceptual and intellectual, as well as graphic. Her knowledge had to encompass an understanding of the many parts, functions, and interconnections of the repository—but not the technical aspects of implementing their design. She had to understand what structured data can do, but not how to structure data herself.<sup><a href="chapter_5.xhtml#chapter5-12" id="chapter5_12" role="doc-noteref">12</a></sup> More remains to be done to integrate this kind of highly specific approach to location and orientation into visualizations of arguments and evidence.</p>
<p>A striking contrast comes into focus when we compare this site with that of a business systems software “cockpit” and its role in providing a user with a view of a supply chain. In her recent work, digital humanities scholar Miriam Posner has focused on these platforms to show how they <span aria-label="133" id="pg_133" role="doc-pagebreak"/>produce an illusion of omnipotence—the whole world is shown on the screen and every phase of the process can be searched, found, faceted, displayed, pinpointed in real time.<sup><a href="chapter_5.xhtml#chapter5-13" id="chapter5_13" role="doc-noteref">13</a></sup> But what the design of these platforms <i>does</i> is conceal the costs of production—human, labor, environmental, economic, political, and so on. The agency of the designer is in the service of relations between human beings and intelligent systems whose use of neural networks and other capacities for bootstrapping and self-optimization do not depend on people. Once put in place, they work out of sight and, largely, out of control. Design, in this instance, is not a matter of the creation of communications between individuals, or even companies or corporations, but of the surface display of complex systems with which we do not have the power to intervene.<sup><a href="chapter_5.xhtml#chapter5-14" id="chapter5_14" role="doc-noteref">14</a></sup></p>
<p>As we arrive at the end of this critical analysis, we are still left with the dilemma of how to implement design features based on these insights. Can we conceive of models of interface that are genuine instruments for research? That are not merely queries within preset data that search and sort according to an immutable agenda? How can we imagine an interface that allows content modeling, intellectual argument, rhetorical engagement? In such an approach, the formal, graphical materiality of the interface might register the performative dimensions as well as support them. Such approaches would be fundamentally distinct from those in the HCI community. In place of transparency and clarity, they would foreground ambiguity and uncertainty, unresolvable multiplicities in place of singularities and certainties. Sustained interpretative engagement, not efficient completion of tasks, would be the desired outcome. Grounded in principles of interpretation and a theory of subjectivity, such an approach to design has yet to be developed. But it would expose the process of thinking rather than display fixed results of intellectual activity as if they were products.<sup><a href="chapter_5.xhtml#chapter5-15" id="chapter5_15" role="doc-noteref">15</a></sup></p>
<p>Rather than conceive of interface as a threshold, a liminal zone, a space between, it should be thought of as a constitutive space of enunciation, not simply a gap between one thing and another thing, a user and an operating system, in a mechanistic sense, but a mediating, transacting, <i>productive</i> space. Lori Emerson commented on the ways this approach allows the discursive power of interface to be apprehended. “It also seems to me that an attention to interface—again, made possible through attention to certain works of e-literature—is a crucial tool in our arsenal against a receding present <span class="ellipsis">…</span> by which I mean without attention to the ways in which present and past <span aria-label="134" id="pg_134" role="doc-pagebreak"/>writing interfaces frame what can and cannot be said, the contemporary computing industry will only continue un-checked in its accelerating drive to achieve perfect invisibility through multi-touch, so-called Natural User Interfaces, and ubiquitous computing devices.”<sup><a href="chapter_5.xhtml#chapter5-16" id="chapter5_16" role="doc-noteref">16</a></sup></p>
<p>The challenge of creating an interface in which the performative character of interpretation can be supported and registered builds on demonstrable principles: multiple points of view, correlatable displays, aggregated data, social mediation, and networking as a feature of scholarly work, and the qualities of games with emerging rule sets.<sup><a href="chapter_5.xhtml#chapter5-17" id="chapter5_17" role="doc-noteref">17</a></sup> These features, like those discussed in the section dealing with hermeneutics, are elements that fracture the singularity of interface, allow situatedness and constructed positionality to be registered, and force the user to confront their subject identity as an aspect of their experience. Within a humanistic environment, the need to record subject position and authorship and offer multiple perspectives of critical reading and interpretative pathways through the complexities of the cultural record also requires new approaches to interface design.</p>
<p>The interface makes a visual contract between maker and viewer, between the display and the subject positions it constructs. A humanistic interface might, at the very least, unmask those workings and allow subjects to inscribe themselves within its frames, to note, mark, acknowledge, and even respond to the enunciative apparatus, to allow spoken subjects to begin to understand the position they occupy and the illusions of agency this position promotes.</p>
</section>
</section>
<section epub:type="division">
<h2 class="head a-head"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Summary</samp></h2>
<p class="noindent">All of these projects make use of nonrepresentational approaches. Modeling tools involve the direct use of graphic manipulation to structure arguments, rather than simply providing a display. Nonrepresentational approaches use graphical means as primary instruments in production of arguments, but their relational and structural capacities can be used in display as well. The primary modeling function allows data structures and values to be generated from graphical manipulation. The components of a nonrepresentational system were described in a previous section. These features allow connections, organization (juxtaposition, sequencing, ordering, stacking, hierarchy) and other arrangements meant to be read semantically and rhetorically. The components of the system include layering, point of view systems, attributes (of completeness, uncertainty, ambiguity, and other features customizable <span aria-label="135" id="pg_135" role="doc-pagebreak"/>by the user). The system was designed to assist in graphic display and interrogation/manipulation of elaborately marked-up narratives.<sup><a href="chapter_5.xhtml#chapter5-18" id="chapter5_18" role="doc-noteref">18</a></sup> Temporal modeling provides an example of a project that makes similar use of graphical elements and direct manipulation as acts of interpretation. In all cases, the system structure is the same: graphical features combine with elements that add affective value, meaning through relations, and other argument structures created directly. These all have conceptual dimensions and implications. The graphical features are a set of elements with which to make direct interpretative actions using visual moves. Various features that draw on pictorial conventions, such as parallax and perspective, are incorporated for interpretative purposes. The graphical elements are culled from Jacques Bertin’s foundational work on static graphics (size, shape, color, texture, position, orientation, and tone) with additional dynamic, animating elements that were not part of his system (change in size, position, orientation, speed, direction, etc.). Other elements would be borrowed from physics engines and animation software, such as bounce, repulsion, attraction, torque, weight, force, and so forth, to add features to the set of components to be used in interpretative activity. Though none of these features are meant to carry an inherent semantic value, they do conjure associations and can be used to create interpretative effects. Attributes can be used to signal qualitative value, even if they are given quantitative measure. These could be put at the service of intellectual schema, but also subjective assessments of pleasantness, anxiety, fear, distaste, and so on depending on the requirements of a project and the tasks of the scholar. The system includes activators and inflectors, or syntactic and semantic inflections. Activators are relational (such as contradiction or similarity) and inflectors are largely semantic attributes (such as salience or ambiguity).</p>
<p>The dimensions of the system are meant to activate the potential of visual conventions in the service of interpretation. These include point of view, layers, slices, shifts in viewpoint such as tilt, splitting, folding, projecting, presentation from parallax views, and relative scales put into comparison. Annotation can be attached to any feature. The justification for these elements is to allow a researcher to expose features of the data through graphic manipulation and thus to discover aspects of data otherwise unseen or hidden in standard displays.</p>
<p>The distinguishing feature of nonrepresentational approaches to modeling interpretation is that these reverse the standard sequence. Visualizations <span aria-label="136" id="pg_136" role="doc-pagebreak"/>usually begin with data and then generate a visualization as an output using some regular convention such as a bar chart, line graphs, network diagram, and so on. But the nonrepresentational approach allows direct data production through graphical input and inflection. The direct manipulation also suggests that graphical organization, arrangement, manipulation, and features constitute arguments. The ordering of a set of documents, or the attraction of one piece of evidence to another, is a rhetorical move, and it creates an argument. A nonrepresentational argument space is a familiar feature of the analogue desktop where we arrange our papers for use, or the space of the now largely defunct slide table, where the spatialized organization of a lecture took place before being subjected to editing into linear presentation form. These aspects of analogue (and digital) manipulation have not been well integrated into digital humanities research, especially with the goal of making the graphical argument structure a primary method of generating data structures and values.</p>
<p>The projects share a few common features: they use direct methods of graphic activity (manipulating existing forms, objects, screen representations, or surrogates and creating new graphic forms, arrangements, or structures) to perform interpretative acts. These acts are specific to particular humanities research tasks—making timelines, chronologies, spatial representations, maps, networks, or arrangements of documents or other materials as part of an argument—but the tools can be used for tasks concerned with work in other domains (social sciences, policy, emergency management systems and so on). In every case, the graphic manipulation either <i>alters</i> an existing data structure, <i>creates</i> it, or <i>adds</i> to it. In every case, the graphic manipulation can be used to generate a nonstandard metric: a timeline that registers affective impact on relative scales, heterochronologies created according to culturally specific or historical models that do not match current standard western time-keeping, maps that are morphed and warped according to experience or evidence, models of partial knowledge either as percentages of a base reference image or as interconnected fragments constructing an image as an effect. All are premised on a nonrepresentational approach to graphical organization and expression as semantically meaningful as argument structures that make use of organization and arrangement in significant/signifying ways. All are designed to scale, but to work at a very granular, detailed level. All can import structured data and export newly structured data, but the complexity of data <span aria-label="137" id="pg_137" role="doc-pagebreak"/>created in this approach (its inclusion of variables, nonstandard metrical features, and other elements generated within the visualizations) will make it difficult to export to or display in standard, conventional formats—but will add richness and dimensions to its analyses.</p>
<p>These projects and examples cover almost all instances of current conventions for what is commonly referred to as “information visualization” but should more properly be called “graphical expressions of interpretative processes.” They are sketches or outlines for projects that would provide proof of concept of multiple aspects of nonrepresentational approaches to modeling interpretation. All intellectual inquiry that makes use of simple, static visualizations conceals assumptions, procedures, and decisions in representations (constructions) that masquerade as presentations (declarative statements). All visualizations in current use are reifications of misinformation. Epistemologically, this is not a situation that can be corrected, only exposed, by creating a graphical system that demonstrates the hermeneutics of intellectual work as constitutive of its objects of inquiry.</p>
<p>Experimental versions of these approaches are sketched in the appendix.</p>
</section>
<section epub:type="rearnotes" role="doc-endnotes">
<h1 class="BMH1"><samp class="SANS_ITC_Stone_Sans_Std_Semibold_B_11">Notes</samp></h1>
<ol class="footnotes">
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_1" id="chapter5-1">1</a></span>. Concepts like “the spatial turn” assigned to trends in the digital humanities, for instance, are generally referring to an uptake in use of maps, rather than a serious engagement with issues of space and spatiality, their conception across historical and cultural domains, or critical reflection on the definition of these terms.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_2" id="chapter5-2">2</a></span>. Excel and Google Sheets are two outstanding examples, both of which enable a wide variety of visualizations. In <i>Show Me the Numbers</i> (El Dorado Hills, CA: Analytics Press, 2012), Stephen Few demonstrated the versatility and range of Excel’s capabilities by making all of the visualizations in his book within its constraints.</p></li>
<li role="doc-endnote"><p class="endnote"><span aria-label="190" id="pg_190" role="doc-pagebreak"/><span class="en_tx"><a href="chapter_5.xhtml#chapter5_3" id="chapter5-3">3</a></span>. See Johanna Drucker, <i>SpecLab</i> (Chicago: University of Chicago Press, 2009), 37–64, for a description of this project and its development. Temporal modeling was the first project I initiated at the University of Virginia in 1999–2000, and the founding of SpecLab and work on Ivanhoe picked up many of the features in that project in the summer of 2000 and after.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_4" id="chapter5-4">4</a></span>. John David Miller and John Maeda, “A Stitch in Time: Visualizing History through Unit Forms and Repetition Structures” (2015), <a href="https://www.researchgate.net/publication/277250414_A_Stitch_in_Time_Visualizing_History_Through_Unit_Forms_and_Repetition_Structures">https://www.researchgate.net/publication/277250414_A_Stitch_in_Time_Visualizing_History_Through_Unit_Forms_and_Repetition_Structures</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_5" id="chapter5-5">5</a></span>. J. T. Fraser, <i>Time, the Familiar Stranger</i> (Amherst: University of Massachusetts Press, 1987); and J. T. Fraser, Marlene P. Soulsby, and Alexander Argyros, eds., <i>Time, Order, Chaos: The Study of Time</i> (Madison, CT: International Universities Press, 1998).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_6" id="chapter5-6">6</a></span>. See Drucker, <i>SpecLab</i>, 48, and 50–51, for specifics.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_7" id="chapter5-7">7</a></span>. Working with a small team (Maura Tarnoff, Bethany Novwiskie, and Jim Allman, as well as Louise Sandhaus and a group of her students at CalArts).</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_8" id="chapter5-8">8</a></span>. In essence, this is what the individual viewpoints in Ivanhoe, in combination with the log and now-slider, permitted. See Johanna Drucker, “Designing Ivanhoe,” <i>Text Technology</i>, no. 2 (2003), <a href="http://www.t5d.com/tt/2004/pdf/vol12_2_03.pdf">http://www.t5d.com/tt/2004/pdf/vol12_2_03.pdf</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_9" id="chapter5-9">9</a></span>. Martin J. S. Rudwick, <i>Scenes from Deep Time: Early Pictorial Representations of the Prehistoric World</i> (Chicago: University of Chicago Press, 1992); for a description of the discovery of “Deep Time,” see M. Alan Kazlev’s site: <a href="http://palaeos.com/timescale/historical/index.html">http://palaeos.com/timescale/historical/index.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_10" id="chapter5-10">10</a></span>. See Robert D. Montoya and Seth R. Erickson, “Anachronism in Global Information Systems: The Cases of Catalogue of Life and Unicode,” <a href="https://www.ideals.illinois.edu/bitstream/handle/2142/98866/2pt13_Montoya-Anachronism.pdf?sequence=1">https://www.ideals.illinois.edu/bitstream/handle/2142/98866/2pt13_Montoya-Anachronism.pdf?sequence=1</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_11" id="chapter5-11">11</a></span>. <i>Die Fackel</i> online, <a href="https://archive.org/details/diefackel64krauuoft">https://archive.org/details/diefackel64krauuoft</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_12" id="chapter5-12">12</a></span>. Johanna Drucker, “Design Agency,” <i>Dialectic</i> 1, no. 2 (2017), 11–16.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_13" id="chapter5-13">13</a></span>. Posner, in presentation, UCLA, 2016. No online or published version exists, nor does she cite this on her resume, but the work made a vivid and important argument about supply chains and about the interface software that is an industry standard.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_14" id="chapter5-14">14</a></span>. Drucker, “Design Agency.”</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_15" id="chapter5-15">15</a></span>. See Johanna Drucker, “Performative Materiality and Theoretical Approaches to Interface,” <i>DHQ</i> (<i>Digital Humanities Quarterly</i>) 7, no. 1 (Summer 2013), <a href="http://www.digitalhumanities.org/dhq/vol/7/1/000143/000143.html">http://www.digitalhumanities.org/dhq/vol/7/1/000143/000143.html</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_16" id="chapter5-16">16</a></span>. Lori Emerson, <a href="https://loriemerson.net/tag/digital-poetry/">https://loriemerson.net/tag/digital-poetry/</a>.</p></li>
<li role="doc-endnote"><p class="endnote"><span aria-label="191" id="pg_191" role="doc-pagebreak"/><span class="en_tx"><a href="chapter_5.xhtml#chapter5_17" id="chapter5-17">17</a></span>. Drucker, “Performative Materiality.”</p></li>
<li role="doc-endnote"><p class="endnote"><span class="en_tx"><a href="chapter_5.xhtml#chapter5_18" id="chapter5-18">18</a></span>. The CATMA system, developed at Hamburg University by Jan Christoph Meister’s team.</p></li>
</ol>
</section>
</section>
</div>
</body>
</html>